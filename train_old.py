"""
CaMoE v10.7 è®­ç»ƒè„šæœ¬ (Final Fix)
é€‚é…: æœ¬åœ°Dataset / BF16 / Checkpointing / Gather-Scatter
"""

import os
import time
import argparse
import torch
from torch.nn.utils import clip_grad_norm_
from torch.utils.data import DataLoader
from datasets import load_from_disk
import bitsandbytes as bnb

try:
    import swanlab
    HAS_SWANLAB = True
except ImportError:
    HAS_SWANLAB = False

from camoe import CaMoE_System
from config import CONFIG_01B, CONFIG_04B

try:
    from tokenizer.rwkv_tokenizer import TRIE_TOKENIZER
except ImportError:
    TRIE_TOKENIZER = None


def get_phase(step: int, config: dict) -> str:
    # ç®€å•çš„é˜¶æ®µè°ƒåº¦
    if step < config.get('prewarm_steps', 100):
        return "prewarm"
    if step < config.get('warmup_steps', 500):
        return "warmup"
    return "normal"


def apply_phase(model, optimizer, phase: str, config: dict):
    # åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡å’Œå†»ç»“å‚æ•°
    if phase == "prewarm":
        # é¢„çƒ­æœŸï¼šåªè®­ç»ƒæ–°åŠ çš„å±‚ (Transä¸“å®¶, Bridge)
        for n, p in model.named_parameters():
            should_train = any([
                'experts.' + str(model.num_rwkv_experts) in n,  # Transä¸“å®¶
                'bridge' in n,
                'critic' in n,
                'capital' in n
            ])
            p.requires_grad = should_train
        lr = config.get('lr_prewarm', 1e-4)
    elif phase == "warmup":
        # å…¨é‡é¢„çƒ­
        for p in model.parameters():
            p.requires_grad = True
        lr = config.get('lr_warmup', 2e-4)
    else:
        # æ­£å¸¸è®­ç»ƒ
        for p in model.parameters():
            p.requires_grad = True
        lr = config.get('lr_normal', 3e-4)
    
    # æ›´æ–°ä¼˜åŒ–å™¨LR
    for pg in optimizer.param_groups:
        pg['lr'] = lr


def load_weights(model, path):
    """ä» RWKV åº•æ¨¡åŠ è½½æƒé‡"""
    if not os.path.exists(path):
        print(f"âš ï¸ Weights not found: {path} (Starting from scratch)")
        return
    
    print(f"ğŸ“¦ Loading backbone from {path}...")
    official = torch.load(path, map_location='cpu', weights_only=True)
    my_dict = model.state_dict()
    loaded = 0
    
    for k, v in official.items():
        # 1. ç›´æ¥åŒ¹é…çš„å±‚ (LN, Embedding, Head)
        if k in my_dict and my_dict[k].shape == v.shape:
            my_dict[k].copy_(v)
            loaded += 1
            continue
        
        # 2. Expert æ˜ å°„ (æŠŠ RWKV Block é‡Œçš„ FFN æƒé‡å¤åˆ¶ç»™ RWKV ä¸“å®¶)
        # RWKV-6/7 Block é€šå¸¸åŒ…å«: att (TimeMix) å’Œ ffn (ChannelMix)
        if 'blocks' in k:
            try:
                # k ä¾‹å­: blocks.0.ffn.key.weight
                parts = k.split('.')
                lid = int(parts[1])
                layer_type = parts[2] # att or ffn
                
                # Backbone (TimeMix) ç›´æ¥åŠ è½½
                if layer_type == 'att':
                    # é‡æ–°ç»„è£…åå­—: blocks.0.att.xxx
                    target_name = f"blocks.{lid}.att.{'.'.join(parts[3:])}"
                    if target_name in my_dict and my_dict[target_name].shape == v.shape:
                        my_dict[target_name].copy_(v)
                        loaded += 1
                
                # FFN -> å¤åˆ¶ç»™æ‰€æœ‰ RWKV Experts
                elif layer_type == 'ffn':
                    # parts[3] å¯èƒ½æ˜¯ key.weight, value.weight, receptance.weight
                    param_name = '.'.join(parts[3:])
                    
                    # éå†æ‰€æœ‰ RWKV ä¸“å®¶
                    for i in range(model.num_rwkv_experts):
                        # æ„é€ ç›®æ ‡åå­—: blocks.0.experts.0.key.weight
                        # æ³¨æ„ï¼šRWKV7 FFN ä¸“å®¶é‡Œå¯èƒ½å« key/valueï¼Œåº•æ¨¡é‡Œå¯èƒ½å« key/receptance
                        # è¿™é‡Œåšä¸€ä¸ªç®€å•çš„æ˜ å°„å°è¯•
                        target = f"blocks.{lid}.experts.{i}.{param_name}"
                        
                        if target in my_dict and my_dict[target].shape == v.shape:
                            # åŠ ä¸Šå¾®å°å™ªå£°ï¼Œè®©ä¸“å®¶åˆå§‹çŠ¶æ€ç•¥æœ‰ä¸åŒ
                            noise = torch.randn_like(v) * 0.01
                            my_dict[target].copy_(v + noise)
                            # åªè®¡æ•°ä¸€æ¬¡ï¼Œé¿å…æ‰“å°å¤ªå¤š
                            if i == 0: loaded += 1
            except Exception as e:
                pass
    
    model.load_state_dict(my_dict, strict=False)
    print(f"âœ… Loaded matching tensors (~{loaded})")


def log_gpu():
    if torch.cuda.is_available():
        alloc = torch.cuda.memory_allocated() / 1024**3
        total = torch.cuda.get_device_properties(0).total_memory / 1024**3
        return f"GPU: {alloc:.1f}/{total:.1f}GB"
    return ""


# æ— é™æ•°æ®åŠ è½½å™¨
def infinite_loader(loader):
    while True:
        for batch in loader:
            yield batch

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--scale", default="0.1b", choices=["0.1b", "0.4b"])
    args = parser.parse_args()
    
    config = CONFIG_01B if args.scale == "0.1b" else CONFIG_04B
    
    # å¼ºåˆ¶è¦†ç›–ä¸€äº›å‚æ•°ä»¥é€‚åº”æ˜¾å­˜
    config['num_rwkv_experts'] = 3 # ä¿æŒä½ çš„è®¾ç½®
    config['micro_batch_size'] = 6 # å¦‚æœæ˜¾å­˜å¤Ÿå¤§ï¼Œå¯ä»¥æ”¹å¤§
    config['grad_accum'] = 8       # æ¢¯åº¦ç´¯ç§¯
    config['total_steps'] = 20000
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    torch.set_float32_matmul_precision('high')
    
    # 1. åŠ è½½ Tokenizer (ä»…ç”¨äº Logging æ–‡æœ¬è¿˜åŸï¼Œä¸ç”¨äºè®­ç»ƒ)
    if TRIE_TOKENIZER and os.path.exists(config['vocab_file']):
        tokenizer = TRIE_TOKENIZER(config['vocab_file'])
        print("âœ… Tokenizer loaded")
    else:
        print("âš ï¸ Tokenizer not found (Logging will be silent)")
        tokenizer = None

    # 2. åŠ è½½æ•°æ®é›†
    print("ğŸš€ Loading pre-processed dataset from disk...")
    try:
        dataset = load_from_disk("./data/tinystories_processed")
        dataset.set_format(type="torch", columns=["input_ids"])
        print(f"ğŸ“Š Dataset Size: {len(dataset)} sequences")
    except Exception as e:
        print(f"âŒ Error loading dataset: {e}")
        return

    # 3. DataLoader
    def simple_collate(batch):
        input_ids = [item["input_ids"] for item in batch]
        max_len = max(len(ids) for ids in input_ids)
        # æˆªæ–­åˆ° config['ctx_len'] + 1 (å› ä¸ºè¦æœ‰ target)
        max_len = min(max_len, config['ctx_len'] + 1)
        
        CHUNK_LEN = 16
        # è®¡ç®—è¾“å…¥éƒ¨åˆ†éœ€è¦çš„é•¿åº¦ (å‘ä¸Šå–æ•´åˆ° 16 çš„å€æ•°)
        input_len = ((max_len - 1 + CHUNK_LEN - 1) // CHUNK_LEN) * CHUNK_LEN
        # åŠ ä¸Š target çš„ 1 ä½
        target_len = input_len + 1
        
        # ç¡®ä¿ä¸çŸ­äºæœ€å°é•¿åº¦ (è‡³å°‘è¦è·‘ä¸€ä¸ª chunk)
        target_len = max(target_len, CHUNK_LEN + 1)
        
        padded_batch = torch.zeros(len(batch), target_len, dtype=torch.long)
        for i, ids in enumerate(input_ids):
            # æˆªæ–­
            l = min(len(ids), target_len)
            padded_batch[i, :l] = ids[:l]
            
        return padded_batch
    train_loader = DataLoader(
        dataset, 
        batch_size=config['micro_batch_size'], 
        shuffle=True, 
        num_workers=0, 
        collate_fn=simple_collate,
        pin_memory=True
    )
    
    # è½¬æ¢ä¸ºæ— é™è¿­ä»£å™¨
    train_iter = infinite_loader(train_loader)

    print("âœ… DataLoader ready. Starting training loop...")
    
    # 4. æ¨¡å‹åˆå§‹åŒ–
    model = CaMoE_System(config).to(device)
    
    # å¼€å¯æ˜¾å­˜ä¼˜åŒ–
    model.gradient_checkpointing_enable()
    
    # åŠ è½½æƒé‡
    load_weights(model, config['weights_path'])
    
    print(f"ğŸ“Š Model params: {sum(p.numel() for p in model.parameters())/1e6:.1f}M")
    print(f"   {log_gpu()}")
    
    # ä¼˜åŒ–å™¨
    optimizer = bnb.optim.AdamW8bit(model.parameters(), lr=config['lr_prewarm'])
    
    if HAS_SWANLAB:
        swanlab.init(project=config['project'], name=config['run_name'], config=config)
    
    os.makedirs(config['save_dir'], exist_ok=True)
    
    print(f"ğŸš€ Training on {device} for {config['total_steps']} steps")
    
    # 5. è®­ç»ƒå¾ªç¯
    for step in range(config['total_steps']):
        t0 = time.time()
        
        # é˜¶æ®µè°ƒåº¦
        phase = get_phase(step, config)
        apply_phase(model, optimizer, phase, config)
        
        # è·å–æ•°æ® (ä» DataLoader)
        try:
            x_batch = next(train_iter)
        except StopIteration:
            # ç†è®ºä¸Šä¸ä¼šå‘ç”Ÿï¼Œå› ä¸ºæ˜¯ infinite_loader
            print("âš ï¸ Data exhausted, restarting iterator...")
            train_iter = infinite_loader(train_loader)
            x_batch = next(train_iter)
            
        x_batch = x_batch.to(device)
        
        # ç¡®ä¿æ•°æ®å¤Ÿé•¿
        if x_batch.shape[1] <= 1:
            continue
            
        x, y = x_batch[:, :-1], x_batch[:, 1:]
        
        # Forward (æ··åˆç²¾åº¦)
        with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):
            logits, info = model(x, step=step, phase=phase)
            total_loss, token_losses, main_loss, critic_loss = model.compute_losses(logits, y, info)
            
            # æ¢¯åº¦ç´¯ç§¯å¹³å‡
            loss_to_backward = total_loss / config['grad_accum']
        
        # Backward
        loss_to_backward.backward()
        
        # Optimizer Step
        if (step + 1) % config['grad_accum'] == 0:
            clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
            optimizer.zero_grad()
            
            # æ›´æ–°å¸‚åœº (ä»…åœ¨ Normal é˜¶æ®µ)
            if phase == "normal" and step > 100:
                model.update_market(info, token_losses, step)
        
        # Logging
        if step % 10 == 0: # ç¨å¾®é¢‘ç¹ä¸€ç‚¹ï¼Œæ–¹ä¾¿çœ‹åˆæœŸæ•ˆæœ
            dt = time.time() - t0
            stats = model.log_market_health()
            
            # è®¡ç®— Tokens Per Second
            tps = config['micro_batch_size'] * x.shape[1] / dt
            
            # æ‹¿åˆ° Trans ä¸“å®¶çš„ä»½é¢ (å¦‚æœæœ‰çš„è¯)
            trans_share = stats.get("L0/TransShare", 0)
            if isinstance(trans_share, torch.Tensor): trans_share = trans_share.item()
            
            print(f"Step {step} | Loss: {main_loss.item():.3f} | "
                  f"Trans%: {trans_share:.2f} | TPS: {tps:.0f} | "
                  f"[{phase.upper()}] | {log_gpu()}")
            
            if HAS_SWANLAB:
                swanlab.log({
                    "Loss/Main": main_loss.item(),
                    "Loss/Critic": critic_loss.item() if isinstance(critic_loss, torch.Tensor) else critic_loss,
                    "Speed/TPS": tps,
                    **stats
                })
        
        # Save
        if step > 0 and step % 2000 == 0:
            path = os.path.join(config['save_dir'], f"v10_step{step}.pth")
            torch.save(model.state_dict(), path)
            print(f"ğŸ’¾ Saved: {path}")
    
    torch.save(model.state_dict(), os.path.join(config['save_dir'], "v10_final.pth"))
    print("ğŸ‰ Done!")


if __name__ == "__main__":
    main()