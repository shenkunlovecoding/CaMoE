"""
CaMoE v12.0 ä¸»ç³»ç»Ÿ
ç‰¹æ€§ï¼š
1. æ··åˆæ¶æ„æ”¯æŒï¼šåŠ¨æ€é…ç½® RWKV ä¸“å®¶æ•°å’Œ Transformer ä¸“å®¶æ•° (å¦‚ 2+2)
2. å…±äº« Bridgeï¼šæ‰€æœ‰ Transformer ä¸“å®¶å…±äº«åŒä¸€ä¸ª Bridge å®ä¾‹ï¼ŒèŠ‚çœæ˜¾å­˜å¹¶é›†ä¸­è®­ç»ƒ
3. æŒç»­å­¦ä¹ ï¼šBridge åœ¨æ¯ä¸€æ­¥éƒ½è®¡ç®—é‡æ„ Lossï¼Œæ— è®ºèƒœè€…æ˜¯è°
4. Eureka ä¸‹æ”¾ï¼šä¼˜åŒ–è®¡ç®—æ•ˆç‡
"""

import torch
import torch.nn as nn
from torch.nn import functional as F
from typing import Dict, Tuple, List
from camoe.backbone import RWKV7_TimeMix
from camoe.bridge import UltimateBridge
from camoe.experts import SparseRWKVFFN, LinearTransformerExpert
from camoe.critic import CriticVC
from camoe.market import CapitalManager, SparseRouter, EurekaController


class CaMoE_Block(nn.Module):
    """
    å•ä¸ªCaMoEå— (æ”¯æŒ Nä¸ªRWKV + Mä¸ªTrans æ··åˆæ¶æ„)
    """
    
    def __init__(self, n_embd: int, n_layer: int, layer_id: int, 
                 head_size: int, config: Dict, bridge: nn.Module):
        super().__init__()
        
        self.layer_id = layer_id
        
        # [æ¶æ„å‡çº§] åŠ¨æ€è¯»å–ä¸“å®¶æ•°é‡
        self.num_rwkv = config.get('num_rwkv_experts', 2)
        self.num_trans = config.get('num_trans_experts', 1) # é»˜è®¤ä¸º1ï¼Œå…¼å®¹æ—§é…ç½®
        self.num_experts = self.num_rwkv + self.num_trans
        
        self.n_embd = n_embd
        self.bridge = bridge # æ¥æ”¶å…±äº«çš„ Bridge
        
        self.ln1 = nn.LayerNorm(n_embd)
        self.ln2 = nn.LayerNorm(n_embd)
        # RWKV-7 TimeMix (System 1 æ°¸è¿œåœ¨çº¿)
        self.att = RWKV7_TimeMix(n_embd, n_layer, layer_id, head_size)
        
        # ä¸“å®¶ç»„æ„å»º
        self.experts = nn.ModuleList()
        
        # 1. System 1: RWKV FFN Experts
        for _ in range(self.num_rwkv):
            self.experts.append(SparseRWKVFFN(n_embd))
            
        # 2. System 2: Transformer Experts (å…±äº«åŒä¸€ä¸ª Bridge)
        for _ in range(self.num_trans):
            self.experts.append(LinearTransformerExpert(
                n_embd, 
                n_head=n_embd//head_size, 
                bridge=self.bridge 
            ))
        
        # Critic è´Ÿè´£é¢„æµ‹æ€»ä¸“å®¶æ•°çš„éš¾åº¦å’Œäº²å’ŒåŠ›
        self.critic = CriticVC(n_embd, self.num_experts)
    
    def forward(self, 
                x: torch.Tensor, 
                v_first: torch.Tensor,
                capital_shares: torch.Tensor,
                router: SparseRouter,
                eureka: EurekaController,
                step: int,
                warmup_steps: int,
                use_market: bool = True,
                training: bool = True) -> Tuple[torch.Tensor, torch.Tensor, Dict]:
        
        B, T, C = x.shape
        
        # 1. TimeMix (Backbone)
        att_out, v_first, rwkv_state = self.att(self.ln1(x), v_first)
        x = x + att_out
        h = self.ln2(x)
        
        # 2. Confidence Calculation (ä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰ä¸“å®¶çš„ä¿¡å¿ƒ)
        # æ³¨æ„ï¼šLinearTransformerExpert.get_confidence ä¹Ÿåªéœ€è¦ hï¼Œä¸éœ€è¦ state
        conf_list = [exp.get_confidence(h) for exp in self.experts]
        confidences = torch.stack(conf_list, dim=-1) # [B, T, E]
        
        # 3. Market / Routing
        if not use_market:
            # Inference / No Market: éšæœºæˆ–åŸºäºè§„åˆ™ï¼Œè¿™é‡Œä¿æŒéšæœº
            winners = torch.randint(0, self.num_experts, (B, T), device=x.device)
            costs = torch.zeros(B, T, device=x.device)
            difficulty = torch.ones(B, T, 1, device=x.device)
            affinity = torch.zeros(B, T, self.num_experts, device=x.device)
        else:
            difficulty, affinity = self.critic(h)
            critic_subsidy = self.critic.apply_to_bids(torch.zeros_like(confidences), affinity)
            winners, costs, bids = router.route(confidences, capital_shares, difficulty, critic_subsidy, training)
            
            # Eureka (æ‰¶è´«æœºåˆ¶)
            if training:
                trigger = eureka.should_trigger(confidences, step, warmup_steps)
                eureka_override = eureka.select_underdog(capital_shares, trigger)
                valid = eureka_override >= 0
                winners = torch.where(valid, eureka_override, winners)
        
        # 4. Bridge æŒç»­å­¦ä¹  (Invisible Training)
        # æ— è®ºè°èƒœå‡ºï¼ŒBridge éƒ½è¦å°è¯•é‡æ„è¾“å…¥ï¼Œä¿æŒæ´»æ€§
        # å³ä½¿è¿™ä¸€å±‚å…¨æ˜¯ RWKV ä¸“å®¶èµ¢äº†ï¼ŒBridge ä¾ç„¶åœ¨è®­ç»ƒï¼Œä¸º Transformer éšæ—¶ä¸Šçº¿åšå‡†å¤‡
        flat_h = h.reshape(-1, C)
        flat_state = rwkv_state.reshape(-1, C)
        _, recon_loss = self.bridge(flat_h, flat_state, return_loss=True)

        # 5. ä¸“å®¶ç¨€ç–æ‰§è¡Œ (Scatter - Compute - Gather)
        flat_winners = winners.reshape(-1)
        
        # æ¢¯åº¦ç›´é€š
        flat_conf = confidences.view(-1, self.num_experts)
        row_idx = torch.arange(flat_h.shape[0], device=x.device)
        winning_conf = flat_conf[row_idx, flat_winners].unsqueeze(-1)
        scale_factor = winning_conf / (winning_conf.detach() + 1e-6)
        
        final_out = torch.zeros_like(flat_h)
        
        for e in range(self.num_experts):
            mask_indices = (flat_winners == e).nonzero(as_tuple=True)[0]
            if mask_indices.numel() == 0: continue
            
            # Gather
            selected_h = flat_h[mask_indices]
            selected_scale = scale_factor[mask_indices]
            
            # [å…³é”®é€»è¾‘] æ ¹æ®ç´¢å¼•åˆ¤æ–­ä¸“å®¶ç±»å‹
            if e >= self.num_rwkv: 
                # System 2: Transformer Experts (éœ€è¦ State é€šè¿‡ Bridge)
                selected_state = flat_state[mask_indices]
                # Expert å†…éƒ¨ä¸å†è®¡ç®— Bridge Lossï¼Œåªä½¿ç”¨ Bridge è¾“å‡º
                expert_out, _ = self.experts[e](selected_h, selected_state)
            else: 
                # System 1: RWKV FFN Experts (ä¸éœ€è¦ State)
                expert_out, _ = self.experts[e](selected_h, None)
            
            # Apply Gradient Scaling & Scatter
            expert_out_scaled = expert_out * selected_scale
            expert_out_scaled = expert_out_scaled.to(dtype=final_out.dtype)
            final_out.index_copy_(0, mask_indices, expert_out_scaled)
            
        out = final_out.reshape(B, T, C)
        x = x + out
        
        info = {
            "winners": winners,
            "costs": costs,
            "difficulty": difficulty,
            "affinity": affinity,
            "recon_loss": recon_loss # å…¨å±€é‡æ„ Loss
        }
        return x, v_first, info


class CaMoE_System(nn.Module):
    def __init__(self, config: Dict):
        super().__init__()
        self.config = config
        self.n_embd = config['n_embd']
        self.n_layer = config['n_layer']
        
        # [æ¶æ„å‡çº§] è®¡ç®—æ€»ä¸“å®¶æ•°
        num_rwkv = config.get('num_rwkv_experts', 2)
        num_trans = config.get('num_trans_experts', 1)
        self.num_experts = num_rwkv + num_trans
        
        self.vocab_size = config['vocab_size']
        self.emb = nn.Embedding(self.vocab_size, self.n_embd)
        
        # å…±äº« Bridge
        self.bridge = UltimateBridge(self.n_embd, config.get('prefix_len', 16))
        
        self.blocks = nn.ModuleList()
        for i in range(self.n_layer):
            self.blocks.append(CaMoE_Block(
                self.n_embd,
                self.n_layer,
                i,
                config['head_size'],
                config,
                bridge=self.bridge 
            ))
        
        self.ln_out = nn.LayerNorm(self.n_embd)
        self.head = nn.Linear(self.n_embd, self.vocab_size, bias=False)
        
        # [å…³é”®ä¿®å¤] CapitalManager ç°åœ¨æ˜¯ nn.Moduleï¼Œç›´æ¥ä½œä¸ºå­æ¨¡å—
        # å®ƒçš„ buffer ä¼šè‡ªåŠ¨åŒ…å«åœ¨ state_dict() ä¸­
        self.capital_manager = CapitalManager(
            self.n_layer, self.num_experts,
            total_capital=config.get('total_capital', 10000.0),
            min_share=config.get('min_capital_share', 0.05),
            tax_threshold=config.get('tax_threshold', 1.5),
            tax_rate=config.get('tax_rate', 0.15)
        )
        
        # åˆ æ‰è¿™å‡ è¡Œï¼Œä¸éœ€è¦äº†ï¼
        # self.register_buffer("market_capitals", ...)
        # self.register_buffer("market_baselines", ...)
        # self.capital_manager.capitals = ...
        
        self.router = SparseRouter()
        self.eureka = EurekaController()
    
    def forward(self, idx: torch.Tensor, step: int = 0, 
                phase: str = "normal") -> Tuple[torch.Tensor, Dict]:
        x = self.emb(idx)
        v_first = None
        use_market = (phase == "normal")
        
        all_info = {
            "winners": [], "costs": [], "difficulties": [], 
            "affinities": [], "recon_losses": []
        }
        warmup_steps = self.config.get('warmup_steps', 2000)

        for i, block in enumerate(self.blocks):
            shares = self.capital_manager.get_shares(i)
            
            # è°ƒç”¨ Block
            x, v_first, info = block(
                x, v_first, shares, self.router, self.eureka, 
                step, warmup_steps, use_market, self.training
            )
            
            all_info["winners"].append(info["winners"].detach())
            all_info["costs"].append(info["costs"].detach())
            all_info["difficulties"].append(info["difficulty"].detach())
            all_info["affinities"].append(info["affinity"].detach())
            all_info["recon_losses"].append(info["recon_loss"])
        
        logits = self.head(self.ln_out(x))
        return logits, all_info
    
    def compute_losses(self, logits, targets, all_info):
        B, T = targets.shape
        
        main_loss = F.cross_entropy(logits.reshape(-1, self.vocab_size), targets.reshape(-1))
        
        with torch.no_grad():
            token_losses = F.cross_entropy(
                logits.reshape(-1, self.vocab_size), targets.reshape(-1), reduction='none'
            ).reshape(B, T)
        
        critic_loss = 0.0
        for i, diff in enumerate(all_info.get("difficulties", [])):
            baseline = self.capital_manager.baseline_losses[i]
            target = F.relu(token_losses - baseline)
            critic_loss += F.smooth_l1_loss(diff.squeeze(-1), target)
        
        if len(all_info.get("difficulties", [])) > 0:
            critic_loss /= len(all_info["difficulties"])

        # Bridge Reconstruction Loss
        bridge_loss = 0.0
        recon_losses = all_info.get("recon_losses", [])
        if recon_losses:
            valid_losses = [l for l in recon_losses if isinstance(l, torch.Tensor)]
            if valid_losses:
                # [ä¿®å¤] ç”¨ sum ä»£æ›¿ stackï¼Œæ›´çœæ˜¾å­˜
                bridge_loss = sum(valid_losses) / len(valid_losses)

        total_loss = main_loss + 0.1 * critic_loss + 0.1 * bridge_loss
        
        return total_loss, token_losses, main_loss, critic_loss, bridge_loss
    
    # update_market å’Œ log_market_health ä¿æŒä¸å˜...
    def update_market(self, all_info, token_losses, step):
        with torch.no_grad():
            for i in range(self.n_layer):
                if i >= len(all_info.get("winners", [])): continue
                
                # 1. æ›´æ–°ä¸“å®¶èµ„æœ¬ (å¸‚åœºæœºåˆ¶)
                self.capital_manager.update(
                    i, all_info["winners"][i], token_losses,
                    all_info["costs"][i], all_info["difficulties"][i]
                )
                
                # 2. æ›´æ–° Critic èµ„æœ¬ (å®è§‚è°ƒæ§)
                baseline = self.capital_manager.baseline_losses[i].item()
                self.blocks[i].critic.settle(
                    all_info["affinities"][i], all_info["winners"][i],
                    token_losses, baseline
                )

                # [æ–°å¢] å¤®è¡Œæ•‘å¸‚ (Bailout) é€»è¾‘
                # å¦‚æœ Critic èµ„æœ¬ä½äº 200 (æ„å‘³ç€æ— æ³•æœ‰æ•ˆå‘æ”¾è¡¥è´´)ï¼Œå¼ºè¡Œæ³¨å…¥ 2000
                if self.blocks[i].critic.capital < 200:
                    self.blocks[i].critic.capital.fill_(2000.0)
                    # æ¯ 100 æ­¥æ‰“å°ä¸€æ¬¡ï¼Œé˜²æ­¢åˆ·å±
                    if step % 100 == 0:
                        print(f"ğŸ›ï¸  Layer {i}: Critic Bailout Triggered (Step {step})")
    
    def log_market_health(self) -> Dict:
        metrics = {}
        check_layers = [0, self.n_layer // 2, self.n_layer - 1]
        check_layers = sorted(list(set([i for i in check_layers if i < self.n_layer])))

        for i in check_layers:
            caps = self.capital_manager.capitals[i]
            # è®¡ç®—æœ€åä¸¤ä¸ªä¸“å®¶ï¼ˆå‡è®¾æ˜¯ Transformerï¼‰çš„ä»½é¢
            # å¦‚æœ num_trans=2, è¿™é‡Œå–æœ€åä¸¤ä¸ª
            # é€šç”¨å†™æ³•ï¼š
            shares = caps / caps.sum() * 100
            
            # Gini
            sorted_caps, _ = torch.sort(caps)
            n = self.num_experts
            idx = torch.arange(1, n + 1, device=caps.device, dtype=caps.dtype)
            gini = ((2 * idx - n - 1) * sorted_caps).sum() / (n * caps.sum() + 1e-6)
            
            # Log Transformer Total Share
            # å‡è®¾ config è¿˜æ²¡ä¼ è¿›æ¥ï¼Œè¿™é‡Œæš‚æ—¶åªæ‰“å°æœ€åä¸€ä¸ªä½œä¸ºå‚è€ƒï¼Œæˆ–è€…å…¨æ‰“
            metrics[f"L{i}/LastExpShare"] = shares[-1].item()
            metrics[f"L{i}/Gini"] = gini.item()
            metrics[f"L{i}/CriticCap"] = self.blocks[i].critic.capital.item()
        
        return metrics