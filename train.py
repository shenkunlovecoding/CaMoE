"""
CaMoE v12.0 è®­ç»ƒè„šæœ¬ (å¸¦ Eval Loss)
æ”¯æŒ: æ–­ç‚¹ç»­è®­ / è‡ªåŠ¨æ­¥æ•°è¯†åˆ« / æ··åˆç²¾åº¦ / æ˜¾å­˜ä¼˜åŒ– / éªŒè¯é›†è¯„ä¼°
"""

import os
import gc
import time
import argparse
import re
import torch
from torch.nn.utils import clip_grad_norm_
from torch.utils.data import DataLoader
from datasets import load_from_disk, Dataset, DatasetDict, interleave_datasets
import bitsandbytes as bnb
from CaMoE.backbone import init_rwkv7_cuda
try:
    import swanlab
    HAS_SWANLAB = True
except ImportError:
    HAS_SWANLAB = False

from CaMoE.system import CaMoE_System
from CaMoE.config import get_config, VERSION


def load_backbone(model, path):
    """ä» RWKV åº•æ¨¡åŠ è½½æƒé‡"""
    if not os.path.exists(path):
        print(f"âš ï¸ Weights not found: {path} (Starting from scratch)")
        return
    
    print(f"ğŸ“¦ Loading backbone from {path}...")
    official = torch.load(path, map_location='cpu', weights_only=True)
    my_dict = model.state_dict()
    loaded = 0
    
    for k, v in official.items():
        if k in my_dict and my_dict[k].shape == v.shape:
            my_dict[k].copy_(v)
            loaded += 1
            continue
        
        if 'blocks' in k:
            try:
                parts = k.split('.')
                lid = int(parts[1])
                layer_type = parts[2]
                
                if layer_type == 'att':
                    target_name = f"blocks.{lid}.att.{'.'.join(parts[3:])}"
                    if target_name in my_dict and my_dict[target_name].shape == v.shape:
                        my_dict[target_name].copy_(v)
                        loaded += 1
                
                elif layer_type == 'ffn':
                    param_name = '.'.join(parts[3:])
                    for i in range(model.num_rwkv_experts):
                        target = f"blocks.{lid}.experts.{i}.{param_name}"
                        if target in my_dict and my_dict[target].shape == v.shape:
                            noise = torch.randn_like(v) * 0.01
                            my_dict[target].copy_(v + noise)
                            if i == 0: loaded += 1
            except Exception as e:
                pass
    
    model.load_state_dict(my_dict, strict=False)
    print(f"âœ… Loaded matching tensors (~{loaded})")

def get_phase(step: int, config: dict) -> str:
    if step < config.get('prewarm_steps', 100):
        return "prewarm"
    if step < config.get('warmup_steps', 500):
        return "warmup"
    return "normal"

def apply_phase(model, optimizer, phase: str, config: dict):
    num_rwkv = config.get('num_rwkv_experts', 2)
    num_trans = config.get('num_trans_experts', 1)
    
    if phase == "prewarm":
        trans_indices = [str(i) for i in range(num_rwkv, num_rwkv + num_trans)]
        for n, p in model.named_parameters():
            is_trans_expert = any(f'experts.{idx}.' in n for idx in trans_indices)
            should_train = any([is_trans_expert, 'bridge' in n, 'critic' in n, 'capital' in n])
            p.requires_grad = should_train
        lr = config.get('lr_prewarm', 1e-4)
        
    elif phase == "warmup":
        for p in model.parameters():
            p.requires_grad = True
        lr = config.get('lr_warmup', 2e-4)
    else:
        for p in model.parameters():
            p.requires_grad = True
        lr = config.get('lr_normal', 3e-4)
    
    for pg in optimizer.param_groups:
        pg['lr'] = lr

def log_gpu():
    if torch.cuda.is_available():
        alloc = torch.cuda.memory_allocated() / 1024**3
        total = torch.cuda.get_device_properties(0).total_memory / 1024**3
        return f"GPU: {alloc:.1f}/{total:.1f}GB"
    return ""

def infinite_loader(loader):
    while True:
        for batch in loader:
            yield batch

def main():
    init_rwkv7_cuda()
    parser = argparse.ArgumentParser()
    parser.add_argument("--scale", default="0.4b", choices=["0.1b", "0.4b"])
    parser.add_argument("--resume", type=str, default=None, help="Path to checkpoint to resume from")
    args = parser.parse_args()
    
    config = get_config(args.scale)
    
    # å¼ºåˆ¶è®¾ç½® Eval é¢‘ç‡
    eval_interval = config.get('eval_interval', 1000)  # æ¯500æ­¥è¯„æµ‹ä¸€æ¬¡
    eval_iters = config.get('eval_iters', 50)         # æ¯æ¬¡è¯„æµ‹è·‘50ä¸ªbatch
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    torch.set_float32_matmul_precision('high')

    # ==========================================
    # 2. Dataset & Splitï¼ˆæ”¯æŒå¤šæ•°æ®é›†æ··åˆï¼Œæ‰‹åŠ¨ Resume æ¢é˜¶æ®µï¼‰
    # ==========================================
    print("ğŸš€ Loading datasets...")
    try:
        mix = config.get("mix")
        data_roots = config.get("data_roots") or {}

        if mix and data_roots:
            # æ··åˆæ¨¡å¼ï¼šæŒ‰ mix æ¯”ä¾‹ interleaveï¼Œè¯¾ç¨‹å­¦ä¹ æ—¶æ”¹ config + Resume å³å¯
            train_datasets = []
            val_datasets = []
            probs = []
            loaded_names = []

            for name, prob in mix.items():
                if prob <= 0:
                    continue
                path = data_roots.get(name)
                if not path or not os.path.exists(path):
                    print(f"âš ï¸ Dataset not found: {path}, skipping {name}.")
                    continue

                ds = load_from_disk(path)
                if isinstance(ds, DatasetDict):
                    tr = ds["train"]
                    va = ds.get("validation") or ds.get("test")
                    if va is None:
                        split = tr.train_test_split(test_size=0.01, seed=42)
                        tr, va = split["train"], split["test"]
                else:
                    split = ds.train_test_split(test_size=0.01, seed=42)
                    tr, va = split["train"], split["test"]

                tr.set_format(type="torch", columns=["input_ids"])
                va.set_format(type="torch", columns=["input_ids"])
                train_datasets.append(tr)
                val_datasets.append(va)
                probs.append(prob)
                loaded_names.append(name)
                print(f"  - {name}: train={len(tr)}, val={len(va)} (prob={prob})")

            if not train_datasets:
                raise ValueError("No valid datasets in mix (paths missing or prob=0).")

            total_p = sum(probs)
            probs = [p / total_p for p in probs]
            train_data = interleave_datasets(train_datasets, probabilities=probs, seed=42,stopping_strategy="all_exhausted")
            val_data = interleave_datasets(val_datasets, probabilities=probs, seed=42,stopping_strategy="all_exhausted")
            print(f"ğŸ“Š Mix: {dict(zip(loaded_names, probs))} â†’ Train={len(train_data)}, Val={len(val_data)}")
        else:
            # å•æ•°æ®é›†
            raw_dataset = load_from_disk(config.get("data_path"))
            if isinstance(raw_dataset, DatasetDict):
                if "validation" in raw_dataset:
                    train_data, val_data = raw_dataset["train"], raw_dataset["validation"]
                elif "test" in raw_dataset:
                    train_data, val_data = raw_dataset["train"], raw_dataset["test"]
                else:
                    split = raw_dataset["train"].train_test_split(test_size=0.05, seed=42)
                    train_data, val_data = split["train"], split["test"]
            elif isinstance(raw_dataset, Dataset):
                split = raw_dataset.train_test_split(test_size=0.05, seed=42)
                train_data, val_data = split["train"], split["test"]
            else:
                raise ValueError("Unknown dataset type")

            train_data.set_format(type="torch", columns=["input_ids"])
            val_data.set_format(type="torch", columns=["input_ids"])
            print(f"ğŸ“Š Dataset Split: Train={len(train_data)}, Val={len(val_data)}")

    except Exception as e:
        print(f"âŒ Error loading dataset: {e}")
        return

    # 3. DataLoader & Collate
    def simple_collate(batch):
        input_ids = [item["input_ids"] for item in batch]
        max_len = max(len(ids) for ids in input_ids)
        max_len = min(max_len, config['ctx_len'] + 1)
        
        # [CUDA Kernel è¦æ±‚] å¯¹é½åˆ° 16 çš„å€æ•° + 1
        CHUNK_LEN = 16
        input_len = ((max_len - 1 + CHUNK_LEN - 1) // CHUNK_LEN) * CHUNK_LEN
        target_len = max(input_len + 1, CHUNK_LEN + 1)
        
        padded_batch = torch.zeros(len(batch), target_len, dtype=torch.long)
        for i, ids in enumerate(input_ids):
            l = min(len(ids), target_len)
            padded_batch[i, :l] = ids[:l]
        return padded_batch

    train_loader = DataLoader(
        train_data, batch_size=config['micro_batch_size'], shuffle=True, 
        num_workers=0, collate_fn=simple_collate, pin_memory=True
    )
    # [æ–°å¢] éªŒè¯é›† Loader
    val_loader = DataLoader(
        val_data, batch_size=config['micro_batch_size'], shuffle=False, 
        num_workers=0, collate_fn=simple_collate, pin_memory=True
    )
    
    train_iter = infinite_loader(train_loader)

    # 4. Model & Optimizer
    print("ğŸ—ï¸ Building model...")
    model = CaMoE_System(config).to(device)
    
    optimizer = bnb.optim.AdamW8bit(model.parameters(), lr=config['lr_prewarm'])

    # ==========================================
    # æ–­ç‚¹ç»­è®­é€»è¾‘
    # ==========================================
        # ==========================================
    # æƒé‡åŠ è½½é€»è¾‘ (é€‚é… MiniPile Init)
    # ==========================================
    start_step = 0
    
    # 1. ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦æœ‰æ˜¾å¼æŒ‡å®šçš„ Resume è·¯å¾„
    resume_path = args.resume
    
    # 2. å¦‚æœæ²¡æŒ‡å®š resumeï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ MiniPile åˆå§‹åŒ–æƒé‡ (æ¸…æ´—ç‰ˆ)
    if not resume_path:
        # å‡è®¾ä½ æŠŠæ¸…æ´—åçš„æƒé‡æ”¾åœ¨è¿™é‡Œï¼Œåå­—å›ºå®š
        minipile_init_path = f"checkpoints/{config['version']}_{config['scale']}/init.pth"
        if os.path.exists(minipile_init_path):
            print(f"âœ¨ Found init checkpoint: {minipile_init_path}")
            resume_path = minipile_init_path
    
    checkpoint = None
    if resume_path and os.path.exists(resume_path):
        print(f"ğŸ“¦ Loading checkpoint from {resume_path}...")
        checkpoint = torch.load(resume_path, map_location='cpu')
        
        # åŠ è½½æ¨¡å‹æƒé‡
        if isinstance(checkpoint, dict) and 'model' in checkpoint:
            # strict=False å…è®¸ä¸€äº›å¾®å°çš„ key å·®å¼‚ï¼Œä½†ä¸»è¦æƒé‡å¿…é¡»åŒ¹é…
            model.load_state_dict(checkpoint['model'], strict=False)
            print("âœ… Model weights loaded.")
            
            # å°è¯•åŠ è½½ä¼˜åŒ–å™¨ (å¦‚æœæœ‰)
            if 'optimizer' in checkpoint:
                try:
                    optimizer.load_state_dict(checkpoint['optimizer'])
                    print("âœ… Optimizer state restored.")
                except Exception as e:
                    print(f"âš ï¸ Optimizer load failed (expected for init weights): {e}")
            else:
                print("â„¹ï¸ No optimizer state found (Fresh start).")
            
            # å°è¯•æ¢å¤æ­¥æ•° (å¦‚æœæ˜¯ init æƒé‡ï¼Œstep åº”è¯¥æ˜¯ 0)
            if 'step' in checkpoint:
                start_step = checkpoint['step']
                # å¦‚æœæ˜¯ step 40000 è¿™ç§ç»“æŸç‚¹ï¼Œæˆ‘ä»¬è¦å¼ºè¡Œé‡ç½®ä¸º 0
                # åªæœ‰å½“å®ƒæ˜¯ä¸­é—´å­˜æ¡£æ—¶æ‰ç»§ç»­
                if "init" in resume_path or start_step >= config['total_steps']:
                    print(f"ğŸ”„ Resetting step from {start_step} to 0 for new training phase.")
                    start_step = 0
                else:
                    start_step += 1
                    print(f"ğŸ”„ Resuming from step {start_step}")
        else:
            # æ—§æ ¼å¼
            model.load_state_dict(checkpoint, strict=False)
            print("âš ï¸ Loaded weights only (Legacy format).")
            
    else:
        # 3. æ—¢æ²¡ Resume ä¹Ÿæ²¡ Initï¼Œæ‰å»åŠ è½½ RWKV åº•æ¨¡
        print("ğŸŒ± No checkpoint found. Loading RWKV backbone...")
        load_backbone(model, config['weights_path'])
    
    # ==========================================
    # [æ–°å¢] è¯„ä¼°å‡½æ•°
    # ==========================================
    @torch.no_grad()
    def estimate_loss(model, loader, eval_steps):
        model.eval()
        losses = []
        val_iter = iter(loader)
        
        for _ in range(eval_steps):
            try:
                batch = next(val_iter)
            except StopIteration:
                val_iter = iter(loader)
                batch = next(val_iter)
            
            batch = batch.to(device)
            if batch.shape[1] <= 1: continue
            
            x, y = batch[:, :-1], batch[:, 1:]
            
            # Eval æ—¶ä½¿ç”¨ Normal æ¨¡å¼ï¼Œæµ‹è¯•å…¨ç³»ç»Ÿ
            with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):
                logits, info = model(x, step=100000, phase="normal") # è¿™é‡Œçš„ step ä¼ å¤§ä¸€ç‚¹ç¡®ä¿è§¦å‘ market
                # åªç®— Main Loss
                loss = torch.nn.functional.cross_entropy(logits.reshape(-1, model.vocab_size), y.reshape(-1))
            
            losses.append(loss.item())
        
        model.train()
        return sum(losses) / len(losses)

    print(f"ğŸ“Š Model params: {sum(p.numel() for p in model.parameters())/1e6:.1f}M")
    
    # ==========================================
    # SwanLab åˆå§‹åŒ– (å¸¦å›¾è¡¨ç»­æ¥åŠŸèƒ½)
    # ==========================================
    current_run_id = None
    run_id = None
    
    # 1. å¦‚æœæ˜¯ Resumeï¼Œå°è¯•ä» checkpoint æ‰¾ run_id
    if args.resume and isinstance(checkpoint, dict) and 'swanlab_run_id' in checkpoint:
        run_id = checkpoint['swanlab_run_id']
        print(f"ğŸ”„ Resuming SwanLab run: {run_id}")
    
    # 2. åˆå§‹åŒ– SwanLab
    if HAS_SWANLAB:
        experiment = swanlab.init(
            project=config['project'],
            name=config['run_name'],
            config=config,
            id=run_id,
            resume="allow"
        )
        # è·å–å½“å‰çš„ run_id (å¦‚æœæ˜¯æ–°çš„ï¼Œè¿™é‡Œä¼šç”Ÿæˆæ–°çš„)
        current_run_id = experiment.run.id
    
    os.makedirs(config['save_dir'], exist_ok=True)
    
    print(f"ğŸš€ Training start from step {start_step}...")
    
    # ==========================================
    # Logging é€»è¾‘ (å›æ»šåˆ°ç¬æ—¶å€¼ + ä¿®å¤Stepæ˜¾ç¤º)
    # ==========================================
    log_interval = config.get('log_interval', 10)
    
    # 5. Training Loop
    for step in range(start_step, config['total_steps']):
        torch.cuda.reset_peak_memory_stats()
        t0 = time.time()
        
        phase = get_phase(step, config)
        apply_phase(model, optimizer, phase, config)
        
        try:
            x_batch = next(train_iter)
        except StopIteration:
            train_iter = infinite_loader(train_loader)
            x_batch = next(train_iter)
            
        x_batch = x_batch.to(device)
        if x_batch.shape[1] <= 1: continue
            
        x, y = x_batch[:, :-1], x_batch[:, 1:]
        
        with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):
            logits, info = model(x, step=step, phase=phase)
            total_loss, token_losses, main_loss, critic_loss ,bridge_loss = model.compute_losses(logits, y, info)
            loss_to_backward = total_loss / config['grad_accum']

        loss_to_backward.backward()
        
        if (step + 1) % config['grad_accum'] == 0:
            clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
            optimizer.zero_grad()
            
            if phase == "normal" and step > 100:
                model.update_market(info, token_losses, step)
        
        # [ä¿®æ”¹] æ—¥å¿—ä¸è¯„ä¼°é€»è¾‘
        if step % log_interval == 0:
            dt = time.time() - t0
            tps = config['micro_batch_size'] * x.shape[1] / dt
            
            # --- è¯„ä¼° ---
            val_loss = None
            if step > 0 and step % eval_interval == 0:
                print(f"ğŸ” Evaluating at step {step}...")
                val_loss = estimate_loss(model, val_loader, eval_iters)
            
            # ç»Ÿè®¡
            stats = model.log_market_health()
            trans_share = stats.get("L0/TransShare", 0)
            if isinstance(trans_share, torch.Tensor): trans_share = trans_share.item()
            
            # æ‰“å° (ç¬æ—¶ Loss)
            log_str = f"Step {step} | Loss: {main_loss.item():.3f}"
            if val_loss:
                log_str += f" | ValLoss: {val_loss:.3f}"
            log_str += f" | Trans%: {trans_share:.1f} | TPS: {tps:.0f} | [{phase.upper()}]"
            print(log_str)
            
            # SwanLab Log (å…³é”®ä¿®æ­£ï¼šä¼ å…¥ step å‚æ•°)
            if HAS_SWANLAB:
                logs = {
                    "Loss/Train_Main": main_loss.item(),
                    "Loss/Train_Critic": critic_loss.item() if isinstance(critic_loss, torch.Tensor) else critic_loss,
                    "Loss/Train_Bridge" : bridge_loss.item() if isinstance(bridge_loss, torch.Tensor) else bridge_loss,
                    "Speed/TPS": tps,
                    **stats
                }
                if val_loss:
                    logs["Loss/Validation"] = val_loss
                
                # [å…³é”®] æ˜¾å¼æŒ‡å®š stepï¼Œè¿™æ · step 1000 å°±ä¼šç”»åœ¨ X=1000 å¤„
                swanlab.log(logs, step=step)
        
        # ä¿å­˜å®Œæ•´ Checkpoint (é¡ºä¾¿ä¿å­˜ run_id)
        if step > 0 and step % 2000 == 0:
            gc.collect()
            torch.cuda.empty_cache()
            print("ğŸ§¹ Cache cleared")
            path = os.path.join(config['save_dir'], f"{config['version']}_step{step}.pth")
        
            checkpoint_data = {
                'model': model.state_dict(),
                'optimizer': optimizer.state_dict(),
                'step': step,
                'config': config,
                'swanlab_run_id': current_run_id,
                'version': config['version']  # é¢å¤–è®°å½•ç‰ˆæœ¬
            }
            torch.save(checkpoint_data, path)
            print(f"ğŸ’¾ Saved: {path}")
    
    final_path = os.path.join(config['save_dir'], f"{config['version']}_final.pth")
    torch.save(
        {
            'model': model.state_dict(),
            'step': config['total_steps'],
            'config': config,
            'swanlab_run_id': current_run_id,
            'version': config['version'],
        },
        final_path
    )
    print("ğŸ‰ Done!")

if __name__ == "__main__":
    main()