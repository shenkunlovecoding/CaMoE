# lmeval.py â€” lm-evaluation-harness å…¥å£ï¼Œé€‚é… v18 æ¶æ„ä¸è‡ªåŠ¨ç»“æœå‘½å
import os
import sys
import json
import argparse
from datetime import datetime

import torch
from CaMoE.backbone import init_rwkv7_cuda
import lm_eval
from CaMoE.wrapper import CaMoELM


def main():
    parser = argparse.ArgumentParser(description="CaMoE lm-eval: ä½¿ç”¨ get_config(scale) ä¸ checkpoint å†… config åŒ¹é…æ¶æ„")
    parser.add_argument("--pretrained", type=str, default=None, help="Checkpoint è·¯å¾„ï¼Œä¾‹å¦‚ checkpoints/v18_0.4b/v18_step2000.pth")
    parser.add_argument("--scale", type=str, default="0.4b", choices=["0.1b", "0.4b"], help="æœªä» checkpoint è¯» config æ—¶ä½¿ç”¨çš„è§„æ¨¡")
    parser.add_argument("--tasks", type=str, default="arc_easy", help="ä»»åŠ¡åï¼Œé€—å·åˆ†éš”ï¼Œå¦‚ arc_easy,hellaswag")
    parser.add_argument("--batch_size", type=int, default=64, help="è¯„ä¼° batch size")
    parser.add_argument("--output", type=str, default=None, help="ç»“æœ JSON è·¯å¾„ï¼›ä¸æŒ‡å®šåˆ™è‡ªåŠ¨ç”Ÿæˆ results_{version}_{scale}_{tasks}_{timestamp}.json")
    parser.add_argument("--device", type=str, default="cuda")
    args = parser.parse_args()

    tasks_list = [t.strip() for t in args.tasks.split(",") if t.strip()]
    if not tasks_list:
        tasks_list = ["arc_easy"]

    print("â³ Init RWKV-7 CUDA Kernel...")
    init_rwkv7_cuda()
    print("ğŸš€ Loading model...")
    lm = CaMoELM(
        pretrained=args.pretrained,
        scale=args.scale,
        device=args.device,
        batch_size=args.batch_size,
    )
    print("âœ… Model ready!")

    results = lm_eval.simple_evaluate(
        model=lm,
        tasks=tasks_list,
        batch_size=args.batch_size,
    )

    print("\nğŸ“Š ç»“æœ:")
    print(results.get("results", results))

    # è‡ªåŠ¨ç”Ÿæˆ JSON æ–‡ä»¶åï¼šresults_{version}_{scale}_{tasks}_{timestamp}.json
    if args.output:
        out_path = args.output
    else:
        version = lm.config.get("version", "v18")
        scale = lm.config.get("scale", "0.4b")
        task_str = "_".join(tasks_list)[:64]  # é¿å…è¿‡é•¿
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        out_path = f"results_{version}_{scale}_{task_str}_{ts}.json"
    os.makedirs(os.path.dirname(out_path) or ".", exist_ok=True)
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    print(f"ğŸ’¾ Results saved: {out_path}")


if __name__ == "__main__":
    import multiprocessing
    multiprocessing.freeze_support()
    main()
