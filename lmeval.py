# lmeval.py
import os
import sys

print("Step 1: ç¯å¢ƒå˜é‡è®¾ç½®å®Œæˆ")

import torch
print(f"Step 2: PyTorch å¯¼å…¥å®Œæˆ, CUDA={torch.cuda.is_available()}")

print("Step 3: å‡†å¤‡å¯¼å…¥ wrapper...")

# åˆ†æ­¥å¯¼å…¥ï¼Œçœ‹å¡åœ¨å“ª
print("  3.1: å¯¼å…¥ camoe...")
from camoe import CaMoE_System
print("  3.2: å¯¼å…¥ backbone...")
from backbone import init_rwkv7_cuda
print("  3.3: åˆå§‹åŒ– CUDA kernel (å¯èƒ½è¦å‡ åˆ†é’Ÿ)...")
init_rwkv7_cuda()
print("  3.4: å¯¼å…¥ config...")
from config import CONFIG_BABYLM
print("  3.5: å¯¼å…¥ tokenizer...")
from tokenizer.rwkv_tokenizer import TRIE_TOKENIZER

print("Step 4: æ‰€æœ‰å¯¼å…¥å®Œæˆï¼Œå¼€å§‹æ„å»ºæ¨¡å‹...")

import lm_eval
from wrapper import CaMoELM

def main():
    print("ğŸš€ ä¸»è¿›ç¨‹å¯åŠ¨ï¼Œå¼€å§‹åŠ è½½æ¨¡å‹...")
    
    lm = CaMoELM(
        pretrained="checkpoints/babylm/v12_step24000.pth",
        device="cuda",
        batch_size=1,
    )
    print("âœ… Model ready!")

    results = lm_eval.simple_evaluate(
        model=lm,
        tasks=["blimp"],
        batch_size=4,
        limit=100
    )

    print("\nğŸ“Š ç»“æœ:")
    print(results["results"])

if __name__ == "__main__":
    import multiprocessing
    multiprocessing.freeze_support()
    main()