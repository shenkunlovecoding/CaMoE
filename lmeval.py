# lmeval.py
import os
import sys
print("Step 1: ç¯å¢ƒå˜é‡è®¾ç½®å®Œæˆ")

import torch
print(f"Step 2: PyTorch å¯¼å…¥å®Œæˆ, CUDA={torch.cuda.is_available()}")

print("Step 3: å‡†å¤‡å¯¼å…¥ wrapper...")

# åˆ†æ­¥å¯¼å…¥ï¼Œçœ‹å¡åœ¨å“ª
print("  3.1: å¯¼å…¥ camoe...")
from camoe import CaMoE_System
print("  3.2: å¯¼å…¥ backbone...")
from camoe.backbone import init_rwkv7_cuda
print("  3.3: åˆå§‹åŒ– CUDA kernel (å¯èƒ½è¦å‡ åˆ†é’Ÿ)...")
init_rwkv7_cuda()
print("  3.4: å¯¼å…¥ config...")
from camoe.config import CONFIG_MINIPILE
print("  3.5: å¯¼å…¥ tokenizer...")
from tokenizer.rwkv_tokenizer import TRIE_TOKENIZER

print("Step 4: æ‰€æœ‰å¯¼å…¥å®Œæˆï¼Œå¼€å§‹æ„å»ºæ¨¡å‹...")
import json
import lm_eval
from camoe.wrapper import CaMoELM

def main():
    print("ğŸš€ ä¸»è¿›ç¨‹å¯åŠ¨ï¼Œå¼€å§‹åŠ è½½æ¨¡å‹...")
    
    lm = CaMoELM(
        pretrained="checkpoints/minipile/v12_final.pth",
        device="cuda",
        batch_size=1,
    )
    print("âœ… Model ready!")

    results = lm_eval.simple_evaluate(
        model=lm,
        tasks=["arc_easy"],
        batch_size=64
    )

    print("\nğŸ“Š ç»“æœ:")
    print(results["results"])
    with open("results_sst2_38k.json", "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2)
    print("ğŸ’¾ Results cached")

if __name__ == "__main__":
    import multiprocessing
    multiprocessing.freeze_support()
    main()