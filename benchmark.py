"""
CaMoE Benchmark Script
é€‚ç”¨: TinyStoriesV2-GPT4-valid.txt / SlimPajama Validation
åŠŸèƒ½: æµ‹ç®— PPL, TPS, ä»¥åŠå„å±‚ Transformer ä½¿ç”¨ç‡
"""

import torch
import torch.nn.functional as F
import time
import os
import math
from tqdm import tqdm
from camoe import CaMoE_System
from config import CONFIG_01B, CONFIG_04B
from tokenizer.rwkv_tokenizer import TRIE_TOKENIZER

# ================= é…ç½®åŒºåŸŸ =================
# æ•°æ®é›†è·¯å¾„ (è¯·ä¿®æ”¹ä¸ºä½ å®é™…çš„è·¯å¾„)
DATA_PATH = "data/TinyStoriesV2-GPT4-valid.txt" 
MODEL_PATH = "checkpoints/v10_final.pth"
SCALE = "0.1b"
DEVICE = "cuda"
CTX_LEN = 512  # è¯„æµ‹é•¿åº¦
BATCH_SIZE = 4 # å¢å¤§Batch Sizeå¯ä»¥æé«˜è¯„æµ‹é€Ÿåº¦
CHUNK_LEN = 16 # RWKV-7 Kernel çº¦æŸ

# ===========================================

def load_data_generator(path, tokenizer, ctx_len, batch_size):
    """
    æµå¼æ•°æ®åŠ è½½å™¨ï¼Œè‡ªåŠ¨å¯¹é½ CHUNK_LEN
    """
    if not os.path.exists(path):
        print(f"âŒ Error: Dataset not found at {path}")
        return None

    print(f"ğŸ“‚ Reading {path}...")
    with open(path, 'r', encoding='utf-8') as f:
        text = f.read()
    
    print("ğŸ”¤ Tokenizing...")
    tokens = tokenizer.encode(text)
    total_tokens = len(tokens)
    print(f"ğŸ“Š Total tokens in eval set: {total_tokens}")

    # 1. æå¤´å»å°¾ï¼Œä¿è¯æ€»é•¿åº¦èƒ½æ•´é™¤ (Batch * Ctx_len)
    # è™½ç„¶ RWKV Kernel åªéœ€è¦ seq_len å¯¹é½ 16ï¼Œä½†ä¸ºäº† Batch æ•ˆç‡ï¼Œæˆ‘ä»¬è®©æ€»æ•°è§„æ•´
    stride = ctx_len
    num_batches = total_tokens // (batch_size * stride)
    
    # è½¬ä¸º Tensor
    # æˆ‘ä»¬åªå–èƒ½æ•´é™¤çš„éƒ¨åˆ†ï¼Œä¸¢å¼ƒæœ€åä¸€ç‚¹ç‚¹å°¾å·´
    limit = num_batches * batch_size * stride
    data = torch.tensor(tokens[:limit], dtype=torch.long)
    
    # Reshape: [Num_Batches, Batch_Size, Stride]
    data = data.view(num_batches, batch_size, stride)
    
    return data, num_batches

def main():
    # 1. Load Model
    config = CONFIG_01B if SCALE == "0.1b" else CONFIG_04B
    # å¼ºåˆ¶è¦†ç›–é…ç½®ä»¥åŒ¹é…è®­ç»ƒè®¾å®š
    config['num_rwkv_experts'] = 1
    config['ctx_len'] = CTX_LEN
    
    print(f"ğŸ—ï¸ Loading model from {MODEL_PATH}...")
    model = CaMoE_System(config).to(DEVICE)
    
    checkpoint = torch.load(MODEL_PATH, map_location='cpu')
    if 'model' in checkpoint:
        model.load_state_dict(checkpoint['model'])
    else:
        model.load_state_dict(checkpoint)
    
    model.eval()
    
    # 2. Tokenizer
    tokenizer = TRIE_TOKENIZER(config['vocab_file'])
    
    # 3. Data Loader
    data_loader, num_batches = load_data_generator(DATA_PATH, tokenizer, CTX_LEN, BATCH_SIZE)
    if data_loader is None: return

    # 4. Stats Init
    total_nll = 0.0 # Negative Log Likelihood
    total_tokens_processed = 0
    start_time = time.time()
    
    # Transformer Usage Stats
    layer_trans_counts = {i: 0 for i in range(config['n_layer'])}
    total_steps_logged = 0
    
    print(f"ğŸš€ Start Benchmarking (Batches: {num_batches})...")
    
    # 5. Eval Loop
    with torch.no_grad():
        pbar = tqdm(data_loader, total=num_batches, desc="Benchmarking")
        for batch in pbar:
            batch = batch.to(DEVICE)
            # Input: [B, T]
            # Target: æˆ‘ä»¬éœ€è¦é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ã€‚
            # é€šå¸¸ PPL è¯„æµ‹æ˜¯: Input: x[0...T-1], Target: x[1...T]
            # è¿™é‡Œä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬ç›´æ¥æŠŠ Input å–‚è¿›å»ï¼Œç„¶åé”™ä¸€ä½è®¡ç®— Loss
            
            # ç¡®ä¿é•¿åº¦æ˜¯ 16 çš„å€æ•° (è™½ç„¶ CTX_LEN=512 è‚¯å®šæ˜¯ï¼Œä½†ä¸ºäº†ä¿é™©)
            B, T = batch.shape
            if T % CHUNK_LEN != 0:
                # è£æ‰å¤šä½™çš„
                T_new = (T // CHUNK_LEN) * CHUNK_LEN
                batch = batch[:, :T_new]
            
            # Forward
            # step=30000 æ¨¡æ‹Ÿæˆç†Ÿçš„ Market
            logits, info = model(batch, step=30000, phase="normal")
            
            # Shift Logic for Loss
            # Logits: [B, T, V] -> [B, T-1, V]
            # Targets: [B, T]   -> [B, T-1] (shifting right)
            shift_logits = logits[:, :-1, :].contiguous()
            shift_labels = batch[:, 1:].contiguous()
            
            # Calc Loss
            loss = F.cross_entropy(
                shift_logits.view(-1, config['vocab_size']), 
                shift_labels.view(-1), 
                reduction='sum'
            )
            
            # Accumulate
            # loss æ˜¯ sumï¼Œæ‰€ä»¥ç›´æ¥åŠ 
            total_nll += loss.item()
            total_tokens_processed += shift_labels.numel()
            
            # Stats: Transformer Usage
            # info['winners']: List of [B, T]
            transformer_id = config['num_rwkv_experts']
            for layer_idx, winners in enumerate(info['winners']):
                # winners: [B, T]
                # ç»Ÿè®¡æœ‰å¤šå°‘ä¸ª token é€‰äº† Transformer
                usage = (winners == transformer_id).float().mean().item()
                layer_trans_counts[layer_idx] += usage
            
            total_steps_logged += 1
            
            # Update Progress Bar with current PPL
            curr_ppl = math.exp(total_nll / total_tokens_processed)
            pbar.set_postfix({'PPL': f"{curr_ppl:.3f}"})

    # 6. Final Report
    end_time = time.time()
    duration = end_time - start_time
    tps = total_tokens_processed / duration
    
    final_ppl = math.exp(total_nll / total_tokens_processed)
    
    print("\n" + "="*50)
    print(f"ğŸ† BENCHMARK RESULT ({SCALE.upper()})")
    print("="*50)
    print(f"âœ… Final PPL:        {final_ppl:.4f}")
    print(f"â±ï¸  Speed (TPS):      {tps:.0f} tokens/s")
    print(f"ğŸ”¢ Total Tokens:     {total_tokens_processed}")
    print("-" * 50)
    print("ğŸ§  Layer-wise Transformer Usage (Average):")
    
    avg_total_usage = 0
    for i in range(config['n_layer']):
        avg_usage = layer_trans_counts[i] / total_steps_logged
        avg_total_usage += avg_usage
        
        # Visualization
        bar_len = int(avg_usage * 20)
        bar = "â–ˆ" * bar_len + "â–‘" * (20 - bar_len)
        print(f" L{i:02d} | {avg_usage*100:5.1f}% | {bar}")
        
    print("-" * 50)
    print(f"ğŸ’¡ System Average Trans%: {avg_total_usage / config['n_layer'] * 100:.2f}%")
    print("="*50)

if __name__ == "__main__":
    main()