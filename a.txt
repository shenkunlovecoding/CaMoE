train.py:
"""
CaMoE v21 è®­ç»ƒè„šæœ¬
æ”¯æŒ: ä¸ƒé˜¶æ®µè°ƒåº¦ / åˆ†ç»„å­¦ä¹ ç‡ / åˆ†é˜¶æ®µæ•°æ® profile / ç»æµç³»ç»Ÿå¢å¼º / Eval Loss
"""

import os
import gc
import time
import argparse
from typing import Dict, Iterator, List, Tuple, Any
import torch
from torch.nn.utils import clip_grad_norm_
from torch.utils.data import DataLoader
from datasets import load_from_disk, Dataset, DatasetDict, interleave_datasets
import bitsandbytes as bnb
from CaMoE.backbone import init_rwkv7_cuda
try:
    import swanlab
    HAS_SWANLAB = True
except ImportError:
    HAS_SWANLAB = False

from CaMoE.system import CaMoE_System
from CaMoE.config import get_config, VERSION


def load_backbone(model: CaMoE_System, path: str) -> None:
    r"""load_backbone(model, path) -> None

    ä» RWKV åº•æ¨¡è¿ç§»å¯å¯¹é½æƒé‡åˆ° CaMoE æ¶æ„ã€‚

    Args:
      model (CaMoE_System): å½“å‰ CaMoE æ¨¡å‹ã€‚
      path (str): RWKV åº•æ¨¡æƒé‡è·¯å¾„ã€‚
    """
    if not os.path.exists(path):
        print(f"âš ï¸ Weights not found: {path} (Starting from scratch)")
        return
    
    print(f"ğŸ“¦ Loading backbone from {path}...")
    official = torch.load(path, map_location='cpu', weights_only=True)
    my_dict = model.state_dict()
    loaded = 0
    
    for k, v in official.items():
        if k in my_dict and my_dict[k].shape == v.shape:
            my_dict[k].copy_(v)
            loaded += 1
            continue
        
        if 'blocks' in k:
            try:
                parts = k.split('.')
                lid = int(parts[1])
                layer_type = parts[2]
                
                if layer_type == 'att':
                    target_name = f"blocks.{lid}.att.{'.'.join(parts[3:])}"
                    if target_name in my_dict and my_dict[target_name].shape == v.shape:
                        my_dict[target_name].copy_(v)
                        loaded += 1
                
                elif layer_type == 'ffn':
                    param_name = '.'.join(parts[3:])
                    for i in range(model.num_rwkv_experts):
                        target = f"blocks.{lid}.experts.{i}.{param_name}"
                        if target in my_dict and my_dict[target].shape == v.shape:
                            noise = torch.randn_like(v) * 0.01
                            my_dict[target].copy_(v + noise)
                            if i == 0: loaded += 1
            except Exception as e:
                pass
    
    model.load_state_dict(my_dict, strict=False)
    print(f"âœ… Loaded matching tensors (~{loaded})")

def _build_phase_plan(config: Dict) -> List[Dict[str, Any]]:
    schedule = config.get("phase_schedule")
    if schedule:
        plan = []
        cursor = 0
        for phase in schedule:
            item = dict(phase)
            steps = max(0, int(item.get("steps", 0)))
            item["steps"] = steps
            item["start_step"] = cursor
            item["end_step"] = cursor + steps
            item.setdefault("use_market", True)
            item.setdefault("route_grad", True)
            plan.append(item)
            cursor += steps
        return plan

    # å…¼å®¹æ—§é…ç½®ï¼šä¸‰é˜¶æ®µ
    pre = int(config.get("prewarm_steps", 100))
    warm_end = int(config.get("warmup_steps", 500))
    warm = max(0, warm_end - pre)
    total = int(config.get("total_steps", warm_end + 1000))
    normal = max(0, total - warm_end)
    return [
        {
            "name": "prewarm",
            "steps": pre,
            "start_step": 0,
            "end_step": pre,
            "data_profile": "default",
            "train_groups": ["all"],
            "lr_mult": {g: 1.0 for g in config.get("param_groups", [])},
            "market_update": False,
            "use_market": False,
            "route_grad": True,
        },
        {
            "name": "warmup",
            "steps": warm,
            "start_step": pre,
            "end_step": pre + warm,
            "data_profile": "default",
            "train_groups": ["all"],
            "lr_mult": {g: 1.0 for g in config.get("param_groups", [])},
            "market_update": False,
            "use_market": True,
            "route_grad": True,
        },
        {
            "name": "normal",
            "steps": normal,
            "start_step": pre + warm,
            "end_step": pre + warm + normal,
            "data_profile": "default",
            "train_groups": ["all"],
            "lr_mult": {g: 1.0 for g in config.get("param_groups", [])},
            "market_update": True,
            "use_market": True,
            "route_grad": True,
        },
    ]


def _phase_total_steps(phase_plan: List[Dict[str, Any]]) -> int:
    return int(sum(max(0, int(p.get("steps", 0))) for p in phase_plan))


def get_phase(step: int, phase_plan: List[Dict[str, Any]]) -> Dict[str, Any]:
    r"""get_phase(step, phase_plan) -> Dict"""
    for phase in phase_plan:
        if step < phase["end_step"]:
            return phase
    # è¶…èŒƒå›´æ—¶å›é€€æœ€åä¸€ä¸ªæœ‰æ­¥æ•°çš„é˜¶æ®µ
    for phase in reversed(phase_plan):
        if phase.get("steps", 0) > 0:
            return phase
    return phase_plan[-1] if phase_plan else {
        "name": "normal",
        "data_profile": "default",
        "market_update": True,
        "use_market": True,
        "route_grad": True,
    }


def _classify_param_group(name: str, num_rwkv: int) -> str:
    if ".experts." in name and ".confidence." in name:
        return "router_conf"
    if ".critic." in name:
        return "critic"
    if name.startswith("bridge."):
        return "bridge"
    if name.startswith("emb.") or name.startswith("ln_out.") or name.startswith("head.") or name.startswith("deep_embed."):
        return "emb_head"

    if name.startswith("blocks."):
        parts = name.split(".")
        if len(parts) > 3 and parts[2] == "experts":
            try:
                expert_idx = int(parts[3])
                return "rwkv_experts" if expert_idx < num_rwkv else "trans_experts"
            except ValueError:
                pass
        return "rwkv_backbone"

    return "rwkv_backbone"


def build_param_groups(model: CaMoE_System, config: Dict) -> Tuple[List[Dict[str, Any]], Dict[str, List[torch.nn.Parameter]]]:
    r"""build_param_groups(model, config) -> (optimizer_param_groups, group_map)"""
    groups = {g: [] for g in config.get("param_groups", [
        "rwkv_backbone", "router_conf", "rwkv_experts", "trans_experts", "bridge", "critic", "emb_head"
    ])}
    num_rwkv = int(config.get("num_rwkv_experts", 6))

    for name, p in model.named_parameters():
        g = _classify_param_group(name, num_rwkv)
        if g not in groups:
            groups[g] = []
        groups[g].append(p)

    base_lr = float(config.get("base_lr", 1e-4))
    optim_groups = []
    for gname, params in groups.items():
        if not params:
            continue
        optim_groups.append({
            "params": params,
            "lr": base_lr,
            "name": gname,
        })
    return optim_groups, groups


def apply_phase_policy(
    optimizer,
    phase: Dict[str, Any],
    config: Dict,
    group_map: Dict[str, List[torch.nn.Parameter]],
) -> None:
    r"""apply_phase_policy(optimizer, phase, config, group_map) -> None"""
    base_lr = float(config.get("base_lr", 1e-4))
    train_groups = set(phase.get("train_groups", ["all"]))
    train_all = "all" in train_groups
    lr_mult = phase.get("lr_mult", {})

    for gname, params in group_map.items():
        active = train_all or (gname in train_groups)
        for p in params:
            p.requires_grad = active

    for pg in optimizer.param_groups:
        gname = pg.get("name", "")
        mult = float(lr_mult.get(gname, 1.0 if (train_all or gname in train_groups) else 0.0))
        if not (train_all or gname in train_groups):
            mult = 0.0
        pg["lr"] = base_lr * mult


def apply_route_grad_policy(model: CaMoE_System, phase: Dict[str, Any], config: Dict) -> None:
    r"""apply_route_grad_policy(model, phase, config) -> None"""
    default_route_no_grad = bool(config.get("route_no_grad", True))
    route_grad = bool(phase.get("route_grad", not default_route_no_grad))
    route_no_grad = not route_grad

    for block in model.blocks:
        block.route_no_grad = route_no_grad


def _load_profile_datasets(config: Dict, profile_name: str) -> Tuple[Dataset, Dataset]:
    data_profiles = config.get("data_profiles") or {}
    profile = data_profiles.get(profile_name, {})

    if profile_name == "default" and not profile:
        profile = {
            "mix": config.get("mix"),
            "data_path": config.get("data_path"),
        }

    mix = profile.get("mix")
    data_path = profile.get("data_path", config.get("data_path"))
    data_roots = config.get("data_roots") or {}

    if mix and data_roots:
        train_datasets = []
        val_datasets = []
        probs = []
        loaded_names = []

        for name, prob in mix.items():
            if prob <= 0:
                continue
            path = data_roots.get(name)
            if not path or not os.path.exists(path):
                print(f"âš ï¸ Dataset not found: {path}, skipping {name}.")
                continue

            ds = load_from_disk(path)
            if isinstance(ds, DatasetDict):
                tr = ds["train"]
                va = ds.get("validation") or ds.get("test")
                if va is None:
                    split = tr.train_test_split(test_size=0.01, seed=42)
                    tr, va = split["train"], split["test"]
            else:
                split = ds.train_test_split(test_size=0.01, seed=42)
                tr, va = split["train"], split["test"]

            tr.set_format(type="torch", columns=["input_ids"])
            va.set_format(type="torch", columns=["input_ids"])
            train_datasets.append(tr)
            val_datasets.append(va)
            probs.append(float(prob))
            loaded_names.append(name)
            print(f"  - [{profile_name}] {name}: train={len(tr)}, val={len(va)} (prob={prob})")

        if not train_datasets:
            raise ValueError(f"No valid datasets in profile '{profile_name}'.")

        total_p = sum(probs)
        probs = [p / total_p for p in probs]
        train_data = interleave_datasets(
            train_datasets,
            probabilities=probs,
            seed=42,
            stopping_strategy="all_exhausted",
        )
        val_data = interleave_datasets(
            val_datasets,
            probabilities=probs,
            seed=42,
            stopping_strategy="first_exhausted",
        )
        print(f"ğŸ“Š Profile={profile_name} Mix: {dict(zip(loaded_names, probs))} -> Train={len(train_data)}, Val={len(val_data)}")
        return train_data, val_data

    # å•æ•°æ®é›†
    if not data_path:
        raise ValueError(f"Profile '{profile_name}' has no mix and no data_path.")
    raw_dataset = load_from_disk(data_path)
    if isinstance(raw_dataset, DatasetDict):
        if "validation" in raw_dataset:
            train_data, val_data = raw_dataset["train"], raw_dataset["validation"]
        elif "test" in raw_dataset:
            train_data, val_data = raw_dataset["train"], raw_dataset["test"]
        else:
            split = raw_dataset["train"].train_test_split(test_size=0.05, seed=42)
            train_data, val_data = split["train"], split["test"]
    elif isinstance(raw_dataset, Dataset):
        split = raw_dataset.train_test_split(test_size=0.05, seed=42)
        train_data, val_data = split["train"], split["test"]
    else:
        raise ValueError("Unknown dataset type")

    train_data.set_format(type="torch", columns=["input_ids"])
    val_data.set_format(type="torch", columns=["input_ids"])
    print(f"ğŸ“Š Profile={profile_name}: Train={len(train_data)}, Val={len(val_data)}")
    return train_data, val_data


def build_loader_for_profile(
    profile_name: str,
    config: Dict,
    collate_fn,
) -> Tuple[DataLoader, DataLoader]:
    r"""build_loader_for_profile(profile_name, config, collate_fn) -> (train_loader, val_loader)"""
    train_data, val_data = _load_profile_datasets(config, profile_name)
    train_loader = DataLoader(
        train_data,
        batch_size=config["micro_batch_size"],
        shuffle=True,
        num_workers=0,
        collate_fn=collate_fn,
        pin_memory=True,
    )
    val_loader = DataLoader(
        val_data,
        batch_size=config["micro_batch_size"],
        shuffle=False,
        num_workers=0,
        collate_fn=collate_fn,
        pin_memory=True,
    )
    return train_loader, val_loader

def log_gpu() -> str:
    r"""log_gpu() -> str

    è¿”å›å½“å‰ GPU æ˜¾å­˜å ç”¨æ‘˜è¦å­—ç¬¦ä¸²ã€‚

    Returns:
      str: æ˜¾å­˜ä¿¡æ¯ï¼›æ—  CUDA æ—¶è¿”å›ç©ºå­—ç¬¦ä¸²ã€‚
    """
    if torch.cuda.is_available():
        alloc = torch.cuda.memory_allocated() / 1024**3
        total = torch.cuda.get_device_properties(0).total_memory / 1024**3
        return f"GPU: {alloc:.1f}/{total:.1f}GB"
    return ""

def infinite_loader(loader: DataLoader) -> Iterator:
    r"""infinite_loader(loader) -> Iterator

    å°†æœ‰é™ DataLoader åŒ…è£…ä¸ºæ— é™è¿­ä»£å™¨ã€‚

    Args:
      loader (DataLoader): åŸå§‹æ•°æ®åŠ è½½å™¨ã€‚

    Returns:
      Iterator: å¾ªç¯äº§å‡º batch çš„è¿­ä»£å™¨ã€‚
    """
    while True:
        for batch in loader:
            yield batch

def main() -> None:
    r"""main() -> None

    è®­ç»ƒä¸»å…¥å£ï¼ŒåŒ…å«æ•°æ®åŠ è½½ã€æ–­ç‚¹ç»­è®­ã€é˜¶æ®µè®­ç»ƒã€è¯„ä¼°ä¸ä¿å­˜ã€‚
    """
    parser = argparse.ArgumentParser()
    parser.add_argument("--scale", default="0.4b")
    parser.add_argument(
        "--diag",
        default="baseline",
        choices=["baseline", "no_amp", "no_fast_math", "fp32_kernel"],
        help="Diagnostic switches for isolating NaN source",
    )
    parser.add_argument("--resume", type=str, default=None, help="Path to checkpoint to resume from")
    args = parser.parse_args()
    
    config = get_config(args.scale)

    # Diagnostic overrides (switch-only; no model structure changes)
    if args.diag == "no_amp":
        config["train_use_amp"] = False
    elif args.diag == "no_fast_math":
        config["cuda_use_fast_math"] = False
    elif args.diag == "fp32_kernel":
        config["cuda_use_fast_math"] = False
        config["cuda_force_fp32_kernel"] = True

    # Pass diagnostic kernel switches through env for backbone.init_rwkv7_cuda()
    os.environ["CAMOE_DISABLE_FAST_MATH"] = "1" if not config.get("cuda_use_fast_math", True) else "0"
    os.environ["CAMOE_FORCE_FP32_KERNEL"] = "1" if config.get("cuda_force_fp32_kernel", False) else "0"
    os.environ["CAMOE_NAN_DEBUG"] = "1" if config.get("nan_debug", False) else "0"
    os.environ["CAMOE_SANITIZE_TIMEMIX_OUT"] = "1" if config.get("sanitize_timemix_output", False) else "0"
    os.environ["CAMOE_FORCE_TIMEMIX_FALLBACK"] = "1" if config.get("force_timemix_fallback", False) else "0"
    init_rwkv7_cuda()
    
    # å¼ºåˆ¶è®¾ç½® Eval é¢‘ç‡
    eval_interval = config.get('eval_interval', 1000)  # æ¯500æ­¥è¯„æµ‹ä¸€æ¬¡
    eval_iters = config.get('eval_iters', 50)         # æ¯æ¬¡è¯„æµ‹è·‘50ä¸ªbatch
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    torch.set_float32_matmul_precision('high')

    train_use_amp = bool(config.get("train_use_amp", True)) and device == "cuda"
    amp_dtype_name = str(config.get("amp_dtype", "bfloat16"))
    amp_dtype = torch.bfloat16 if amp_dtype_name == "bfloat16" else torch.float16
    print(
        f"ğŸ§ª Diag={args.diag} | AMP={train_use_amp}({amp_dtype_name}) | "
        f"fast_math={config.get('cuda_use_fast_math', True)} | "
        f"fp32_kernel={config.get('cuda_force_fp32_kernel', False)}"
    )

    phase_plan = _build_phase_plan(config)
    config["phase_schedule"] = phase_plan
    total_steps_from_schedule = _phase_total_steps(phase_plan)
    if total_steps_from_schedule > 0:
        config["total_steps"] = total_steps_from_schedule
    phase_to_id = {p.get("name", f"phase_{i}"): i for i, p in enumerate(phase_plan)}

    # 2. DataLoader Collate
    def simple_collate(batch) -> torch.Tensor:
        r"""simple_collate(batch) -> Tensor

        å°†å˜é•¿æ ·æœ¬æ‹¼æ¥ä¸ºå›ºå®šé•¿åº¦ batchï¼Œå¹¶æŒ‰ CUDA kernel çº¦æŸè¿›è¡Œé•¿åº¦å¯¹é½ã€‚

        Args:
          batch: åŸå§‹æ ·æœ¬åˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å« ``input_ids``ã€‚

        Returns:
          Tensor: å½¢çŠ¶ ``[B, T]`` çš„ long å¼ é‡ã€‚
        """
        input_ids = [item["input_ids"] for item in batch]
        max_len = max(len(ids) for ids in input_ids)
        max_len = min(max_len, config['ctx_len'] + 1)
        
        # [CUDA Kernel è¦æ±‚] å¯¹é½åˆ° 16 çš„å€æ•° + 1
        CHUNK_LEN = 16
        input_len = ((max_len - 1 + CHUNK_LEN - 1) // CHUNK_LEN) * CHUNK_LEN
        target_len = max(input_len + 1, CHUNK_LEN + 1)
        
        padded_batch = torch.full((len(batch), target_len), -100, dtype=torch.long)
        for i, ids in enumerate(input_ids):
            l = min(len(ids), target_len)
            padded_batch[i, :l] = ids[:l]
        return padded_batch

    # 3. Model & Optimizer
    print("ğŸ—ï¸ Building model...")
    model = CaMoE_System(config).to(device)

    optimizer_groups, group_map = build_param_groups(model, config)
    optimizer = bnb.optim.AdamW8bit(optimizer_groups, lr=config.get("base_lr", 1e-4))

    # ==========================================
    # æ–­ç‚¹ç»­è®­é€»è¾‘
    # ==========================================
        # ==========================================
    # æƒé‡åŠ è½½é€»è¾‘ (é€‚é… MiniPile Init)
    # ==========================================
    start_step = 0
    
    # 1. ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦æœ‰æ˜¾å¼æŒ‡å®šçš„ Resume è·¯å¾„
    resume_path = args.resume
    
    # 2. å¦‚æœæ²¡æŒ‡å®š resumeï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ MiniPile åˆå§‹åŒ–æƒé‡ (æ¸…æ´—ç‰ˆ)
    if not resume_path:
        # å‡è®¾ä½ æŠŠæ¸…æ´—åçš„æƒé‡æ”¾åœ¨è¿™é‡Œï¼Œåå­—å›ºå®š
        minipile_init_path = f"checkpoints/{config['version']}_{config['scale']}/init.pth"
        if os.path.exists(minipile_init_path):
            print(f"âœ¨ Found init checkpoint: {minipile_init_path}")
            resume_path = minipile_init_path
    
    checkpoint = None
    if resume_path and os.path.exists(resume_path):
        print(f"ğŸ“¦ Loading checkpoint from {resume_path}...")
        checkpoint = torch.load(resume_path, map_location='cpu')
        
        # åŠ è½½æ¨¡å‹æƒé‡
        if isinstance(checkpoint, dict) and 'model' in checkpoint:
            # strict=False å…è®¸ä¸€äº›å¾®å°çš„ key å·®å¼‚ï¼Œä½†ä¸»è¦æƒé‡å¿…é¡»åŒ¹é…
            model.load_state_dict(checkpoint['model'], strict=False)
            print("âœ… Model weights loaded.")
            
            # å°è¯•åŠ è½½ä¼˜åŒ–å™¨ (å¦‚æœæœ‰)
            if 'optimizer' in checkpoint:
                try:
                    optimizer.load_state_dict(checkpoint['optimizer'])
                    print("âœ… Optimizer state restored.")
                except Exception as e:
                    print(f"âš ï¸ Optimizer load failed (expected for init weights): {e}")
            else:
                print("â„¹ï¸ No optimizer state found (Fresh start).")
            
            # å°è¯•æ¢å¤æ­¥æ•° (å¦‚æœæ˜¯ init æƒé‡ï¼Œstep åº”è¯¥æ˜¯ 0)
            if 'step' in checkpoint:
                start_step = checkpoint['step']
                # å¦‚æœæ˜¯ step 40000 è¿™ç§ç»“æŸç‚¹ï¼Œæˆ‘ä»¬è¦å¼ºè¡Œé‡ç½®ä¸º 0
                # åªæœ‰å½“å®ƒæ˜¯ä¸­é—´å­˜æ¡£æ—¶æ‰ç»§ç»­
                if "init" in resume_path or start_step >= config['total_steps']:
                    print(f"ğŸ”„ Resetting step from {start_step} to 0 for new training phase.")
                    start_step = 0
                else:
                    start_step += 1
                    print(f"ğŸ”„ Resuming from step {start_step}")
        else:
            # æ—§æ ¼å¼
            model.load_state_dict(checkpoint, strict=False)
            print("âš ï¸ Loaded weights only (Legacy format).")
            
    else:
        # 3. æ—¢æ²¡ Resume ä¹Ÿæ²¡ Initï¼Œæ‰å»åŠ è½½ RWKV åº•æ¨¡
        print("ğŸŒ± No checkpoint found. Loading RWKV backbone...")
        load_backbone(model, config['weights_path'])

    # ==========================================
    # æŒ‰å½“å‰ step å¯¹é½é˜¶æ®µä¸æ•°æ® profile
    # ==========================================
    current_phase = get_phase(start_step, phase_plan)
    current_profile = current_phase.get("data_profile", "default")
    print(f"ğŸš€ Loading datasets for phase={current_phase.get('name')} profile={current_profile} ...")
    try:
        train_loader, val_loader = build_loader_for_profile(current_profile, config, simple_collate)
    except Exception as e:
        print(f"âŒ Error loading dataset profile '{current_profile}': {e}")
        return
    train_iter = infinite_loader(train_loader)
    
    # ==========================================
    # [æ–°å¢] è¯„ä¼°å‡½æ•°
    # ==========================================
    @torch.no_grad()
    def estimate_loss(model: CaMoE_System, loader: DataLoader, eval_steps: int) -> float:
        r"""estimate_loss(model, loader, eval_steps) -> float

        åœ¨éªŒè¯é›†ä¸Šä¼°ç®—å¹³å‡äº¤å‰ç†µæŸå¤±ã€‚

        Args:
          model (CaMoE_System): å¾…è¯„ä¼°æ¨¡å‹ã€‚
          loader (DataLoader): éªŒè¯é›†åŠ è½½å™¨ã€‚
          eval_steps (int): è¯„ä¼°æ‰¹æ¬¡æ•°ã€‚

        Returns:
          float: å¹³å‡éªŒè¯æŸå¤±ï¼›è‹¥æ— æœ‰æ•ˆå€¼åˆ™è¿”å› ``inf``ã€‚
        """
        model.eval()
        losses = []
        
        # ä½¿ç”¨ itertools.cycle æ— é™å¾ªç¯éªŒè¯é›†ï¼Œé¿å… StopIteration
        from itertools import cycle
        
        for i, batch in enumerate(cycle(loader)):
            if i >= eval_steps:
                break
            
            batch = batch.to(device)
            if batch.shape[1] <= 1: 
                continue
            
            x, y = batch[:, :-1], batch[:, 1:]
            
            # Eval æ—¶ä½¿ç”¨ Normal æ¨¡å¼ï¼Œæµ‹è¯•å…¨ç³»ç»Ÿ
            with torch.amp.autocast(device_type='cuda', dtype=amp_dtype, enabled=train_use_amp):
                logits, info = model(x, step=100000, phase="normal")
                # åªç®— Main Loss
                loss = torch.nn.functional.cross_entropy(
                    logits.reshape(-1, model.vocab_size),
                    y.reshape(-1),
                    ignore_index=-100,
                )
            
            losses.append(loss.item())
            
            # å®‰å…¨æ£€æŸ¥ï¼šå¦‚æœæŸå¤±ä¸º NaN æˆ– Infï¼Œç«‹å³æŠ¥å‘Š
            if not torch.isfinite(torch.tensor(loss.item())):
                print(f"âš ï¸ Invalid loss detected at eval step {i}: {loss.item()}")
                continue
        
        model.train()
        if len(losses) == 0:
            print("âš ï¸ Warning: No valid losses collected during evaluation!")
            return float('inf')
        return sum(losses) / len(losses)

    print(f"ğŸ“Š Model params: {sum(p.numel() for p in model.parameters())/1e6:.1f}M")
    
    # ==========================================
    # SwanLab åˆå§‹åŒ– (å¸¦å›¾è¡¨ç»­æ¥åŠŸèƒ½)
    # ==========================================
    current_run_id = None
    run_id = None
    
    # 1. å¦‚æœæ˜¯ Resumeï¼Œå°è¯•ä» checkpoint æ‰¾ run_id
    if args.resume and isinstance(checkpoint, dict) and 'swanlab_run_id' in checkpoint:
        run_id = checkpoint['swanlab_run_id']
        print(f"ğŸ”„ Resuming SwanLab run: {run_id}")
    
    # 2. åˆå§‹åŒ– SwanLab
    if HAS_SWANLAB:
        experiment = swanlab.init(
            project=config['project'],
            name=config['run_name'],
            config=config,
            id=run_id,
            resume="allow"
        )
        # è·å–å½“å‰çš„ run_id (å¦‚æœæ˜¯æ–°çš„ï¼Œè¿™é‡Œä¼šç”Ÿæˆæ–°çš„)
        current_run_id = experiment.public.run_id
    
    os.makedirs(config['save_dir'], exist_ok=True)
    
    print(f"ğŸš€ Training start from step {start_step}...")
    
    # ==========================================
    # Logging é€»è¾‘ (å›æ»šåˆ°ç¬æ—¶å€¼ + ä¿®å¤Stepæ˜¾ç¤º)
    # ==========================================
    log_interval = config.get('log_interval', 10)
    last_phase_name = None
    active_profile = current_profile
    
    # 5. Training Loop
    for step in range(start_step, config['total_steps']):
        t0 = time.time()
        
        phase = get_phase(step, phase_plan)
        phase_name = phase.get("name", "normal")
        phase_use_market = bool(phase.get("use_market", True))
        if phase_name != last_phase_name:
            apply_phase_policy(optimizer, phase, config, group_map)
            apply_route_grad_policy(model, phase, config)
            last_phase_name = phase_name
            print(
                f"ğŸ” Phase switched -> {phase_name} [{phase.get('start_step', step)}:{phase.get('end_step', step)}] "
                f"| use_market={phase_use_market} | route_grad={phase.get('route_grad', True)}"
            )

            phase_profile = phase.get("data_profile", "default")
            if phase_profile != active_profile:
                print(f"ğŸ§­ Rebuilding dataloaders for profile={phase_profile}")
                train_loader, val_loader = build_loader_for_profile(phase_profile, config, simple_collate)
                train_iter = infinite_loader(train_loader)
                active_profile = phase_profile
        
        try:
            x_batch = next(train_iter)
        except StopIteration:
            train_iter = infinite_loader(train_loader)
            x_batch = next(train_iter)
            
        x_batch = x_batch.to(device)
        if x_batch.shape[1] <= 1: continue
            
        x, y = x_batch[:, :-1], x_batch[:, 1:]
        
        try:
            with torch.amp.autocast(device_type='cuda', dtype=amp_dtype, enabled=train_use_amp):
                logits, info = model(
                    x,
                    step=step,
                    phase=phase_name,
                    use_market_override=phase_use_market,
                )
                total_loss, token_losses, main_loss, critic_loss, aux_loss = model.compute_losses(logits, y, info)
                loss_to_backward = total_loss / config['grad_accum']
        except RuntimeError as e:
            print(f"ğŸ’¥ Forward/LOSS failed at step={step}, phase={phase_name}: {e}")
            raise

        if not torch.isfinite(loss_to_backward):
            print(f"âš ï¸ Non-finite loss at step {step}: {float(loss_to_backward)} (skip batch)")
            optimizer.zero_grad(set_to_none=True)
            continue

        if not loss_to_backward.requires_grad:
            critic_req = critic_loss.requires_grad if isinstance(critic_loss, torch.Tensor) else False
            print(
                f"âš ï¸ No grad graph at step={step}, phase={phase_name} "
                f"(total_loss.requires_grad={total_loss.requires_grad}, critic_loss.requires_grad={critic_req})."
            )
            optimizer.zero_grad(set_to_none=True)
            continue

        loss_to_backward.backward()
        
        if (step + 1) % config['grad_accum'] == 0:
            clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
            optimizer.zero_grad()
            
            if phase.get("market_update", True) and step > 100:
                model.update_market(info, token_losses, step, phase=phase_name, critic_loss=critic_loss)
        
        # [ä¿®æ”¹] æ—¥å¿—ä¸è¯„ä¼°é€»è¾‘
        if step % log_interval == 0:
            dt = time.time() - t0
            tps = config['micro_batch_size'] * x.shape[1] / dt
            
            # --- è¯„ä¼° ---
            val_loss = None
            if step > 0 and step % eval_interval == 0:
                print(f"ğŸ” Evaluating at step {step}...")
                val_loss = estimate_loss(model, val_loader, eval_iters)
            
            # ç»Ÿè®¡
            stats = model.log_market_health()
            
            # æ‰“å° (ç¬æ—¶ Loss)
            log_str = f"Step {step} | Loss: {main_loss.item():.3f}"
            if val_loss:
                log_str += f" | ValLoss: {val_loss:.3f}"
            log_str += f" | TPS: {tps:.0f} | [{phase_name.upper()}]"
            print(log_str)
            
            # SwanLab Log (å…³é”®ä¿®æ­£ï¼šä¼ å…¥ step å‚æ•°)
            if HAS_SWANLAB:
                logs = {
                    "Loss/Train_Main": main_loss.item(),
                    "Loss/Train_Critic": critic_loss.item() if isinstance(critic_loss, torch.Tensor) else critic_loss,
                    "Loss/Aux_Balance": aux_loss.item() if isinstance(aux_loss, torch.Tensor) else aux_loss,
                    "Speed/TPS": tps,
                    "Phase/ID": float(phase_to_id.get(phase_name, -1)),
                    f"Phase/{phase_name}": 1.0,
                    **stats
                }
                if val_loss:
                    logs["Loss/Validation"] = val_loss
                
                # [å…³é”®] æ˜¾å¼æŒ‡å®š stepï¼Œè¿™æ · step 1000 å°±ä¼šç”»åœ¨ X=1000 å¤„
                swanlab.log(logs, step=step)
        
        # ä¿å­˜å®Œæ•´ Checkpoint (é¡ºä¾¿ä¿å­˜ run_id)
        if step > 0 and step % 2000 == 0:
            gc.collect()
            torch.cuda.empty_cache()
            print("ğŸ§¹ Cache cleared")
            path = os.path.join(config['save_dir'], f"{config['version']}_step{step}.pth")
        
            checkpoint_data = {
                'model': model.state_dict(),
                'optimizer': optimizer.state_dict(),
                'step': step,
                'config': config,
                'swanlab_run_id': current_run_id,
                'version': config['version']  # é¢å¤–è®°å½•ç‰ˆæœ¬
            }
            torch.save(checkpoint_data, path)
            print(f"ğŸ’¾ Saved: {path}")
    
    final_path = os.path.join(config['save_dir'], f"{config['version']}_final.pth")
    torch.save(
        {
            'model': model.state_dict(),
            'step': config['total_steps'],
            'config': config,
            'swanlab_run_id': current_run_id,
            'version': config['version'],
        },
        final_path
    )
    print("ğŸ‰ Done!")

if __name__ == "__main__":
    main()


CaMoE/system.py:
"""
CaMoE v21 ä¸»ç³»ç»Ÿ
Changes:
1. åŒé€šé“è·¯ç”±ï¼šGradient Gate + Market Biasã€‚
2. winners ç¦»æ•£é€‰æ‹©ï¼ˆdetachï¼‰ï¼Œweights è¿ç»­å¯å¾®ï¼ˆä¸ detachï¼‰ã€‚
3. æ”¯æŒ phase çº§ use_market_override ä¸ route_grad ç­–ç•¥ã€‚
"""

import torch
import torch.nn as nn
from torch.nn import functional as F
from typing import Dict, Tuple, List
from contextlib import nullcontext
from torch.utils.checkpoint import checkpoint

from .backbone import RWKV7_TimeMix, DeepEmbedAttention, SharedDeepEmbed
from .bridge import UltimateBridge
from .experts import SparseRWKVFFN, LinearTransformerExpert
from .critic import CriticVC
from .market import CapitalManager, SparseRouter

class CaMoE_Block(nn.Module):
    r"""å•ä¸ª CaMoE Blockï¼ŒåŒ…å« TimeMixã€DEA ä¸ Top-2 ä¸“å®¶è·¯ç”±ã€‚"""
    
    def __init__(
        self,
        n_embd: int,
        n_layer: int,
        layer_id: int,
        head_size: int,
        config: Dict,
        bridge: nn.Module,
        shared_deep_embed: nn.Module = None,
    ) -> None:
        r"""åˆå§‹åŒ–å•å±‚ CaMoE Blockã€‚"""
        super().__init__()
        
        self.layer_id = layer_id
        self.num_rwkv = config.get('num_rwkv_experts', 6)
        self.num_trans = config.get('num_trans_experts', 2)
        self.num_experts = self.num_rwkv + self.num_trans
        self.n_embd = n_embd
        self.bridge = bridge
        self.nan_debug = config.get("nan_debug", False)
        use_gc = config.get("use_gradient_checkpoint", True)
        self.checkpoint_att_stage = use_gc and config.get("checkpoint_att_stage", True)
        self.checkpoint_expert_stage = use_gc and config.get("checkpoint_expert_stage", True)
        self.route_no_grad = config.get("route_no_grad", True)
        self.lazy_prefix_union = config.get("lazy_prefix_union", True)
        market_alpha_init = float(config.get("market_alpha_init", 0.05))
        self.register_buffer("market_alpha", torch.tensor([market_alpha_init], dtype=torch.float32))
        
        self.ln1 = nn.LayerNorm(n_embd)
        self.ln2 = nn.LayerNorm(n_embd)
        
        # RWKV-7 TimeMix (Backbone)
        self.att = RWKV7_TimeMix(n_embd, n_layer, layer_id, head_size)
        
        # DeepEmbedAttention (v18.5-test): ä¸ TimeMix å¹¶è¡Œçš„å› æœ Attention åˆ†æ”¯
        self.use_deep_embed_attention = config.get("use_deep_embed_attention", False)
        vocab_size = config.get("vocab_size", 65536)
        if self.use_deep_embed_attention:
            self.dea = DeepEmbedAttention(
                n_embd=n_embd,
                n_layer=n_layer,
                layer_id=layer_id,
                head_size=head_size,
                vocab_size=vocab_size,
                shared_deep_embed=shared_deep_embed,
                q_dim=config.get("dea_q_dim", 256),
                kv_dim=config.get("dea_kv_dim", 32),
                score_scale=config.get("dea_score_scale", 1024.0),
                cap_scale=config.get("dea_cap_scale", 64.0),
            )
        else:
            self.dea = None
        
        # ä¸“å®¶ç»„
        self.experts = nn.ModuleList()
        
        # RWKV FFN Experts
        for _ in range(self.num_rwkv):
            self.experts.append(SparseRWKVFFN(n_embd))
        
        # Transformer Experts
        n_head = n_embd // head_size
        for _ in range(self.num_trans):
            self.experts.append(LinearTransformerExpert(n_embd, n_head))
        
        # Critic
        self.critic = CriticVC(n_embd, self.num_experts)

    def _assert_finite(self, x: torch.Tensor, name: str, step: int) -> None:
        if (not self.nan_debug) or (x is None):
            return
        if not torch.is_floating_point(x):
            return
        if torch.isfinite(x).all():
            return
        with torch.no_grad():
            bad = ~torch.isfinite(x)
            bad_count = int(bad.sum().item())
            total = x.numel()
            finite_x = x[torch.isfinite(x)]
            if finite_x.numel() > 0:
                vmin = float(finite_x.min().item())
                vmax = float(finite_x.max().item())
            else:
                vmin = float("nan")
                vmax = float("nan")
            print(
                f"âŒ NaNDebug-Block | step={step} | block={self.layer_id} | tensor={name} | "
                f"bad={bad_count}/{total} | finite_min={vmin:.6e} | finite_max={vmax:.6e}"
            )
        raise RuntimeError(f"NaN/Inf in block {self.layer_id}, tensor={name}, step={step}")
    
    def _forward_att_stage(
        self,
        x: torch.Tensor,
        v_first: torch.Tensor,
        idx: torch.Tensor,
        step: int,
    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
        r"""æ‰§è¡Œ TimeMix(+DEA) ä¸ ln2ï¼Œè¿”å› x_after_att/h/v_first/rwkv_stateã€‚"""
        self._assert_finite(x, "x_in", step)
        x_ln = self.ln1(x)
        self._assert_finite(x_ln, "x_ln", step)
        att_out, v_first, rwkv_state = self.att(x_ln, v_first)
        self._assert_finite(att_out, "att_out", step)
        self._assert_finite(v_first, "v_first_att", step)
        self._assert_finite(rwkv_state, "rwkv_state", step)
        if self.dea is not None and idx is not None:
            dea_out = self.dea(x_ln, idx)
            self._assert_finite(dea_out, "dea_out", step)
            x_after_att = x + att_out + dea_out
        else:
            x_after_att = x + att_out
        self._assert_finite(x_after_att, "x_after_att", step)
        h = self.ln2(x_after_att)
        self._assert_finite(h, "h_ln2", step)
        return x_after_att, h, v_first, rwkv_state

    def _forward_route_stage(
        self,
        h: torch.Tensor,
        capital_shares: torch.Tensor,
        router: SparseRouter,
        use_market: bool,
        training: bool,
        step: int,
    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
        r"""æ‰§è¡Œ confidence/critic/routerï¼Œè¿”å› winners/weights/costs/difficulty/affinityã€‚"""
        # Gate logits å§‹ç»ˆå¯å¯¼ï¼šç”¨äºè®­ç»ƒ confidence / router
        conf_list = [exp.get_confidence(h) for exp in self.experts]
        gate_logits = torch.stack(conf_list, dim=-1)  # [B, T, E]
        self._assert_finite(gate_logits, "gate_logits", step)

        if not use_market:
            B, T, _E = gate_logits.shape
            capital_bias = torch.zeros_like(gate_logits)
            winners, weights, costs, adjusted_logits = router.route(
                gate_logits=gate_logits,
                capital_bias=capital_bias,
                market_enabled=False,
                training=training,
            )
            difficulty = torch.zeros(B, T, 1, device=h.device, dtype=h.dtype)
            affinity = torch.zeros(B, T, self.num_experts, device=h.device, dtype=h.dtype)
        else:
            route_ctx = torch.no_grad if self.route_no_grad else nullcontext
            with route_ctx():
                route_h = h.detach() if self.route_no_grad else h
                difficulty, affinity = self.critic(route_h)
                self._assert_finite(difficulty, "difficulty", step)
                self._assert_finite(affinity, "affinity", step)
                critic_subsidy = self.critic.subsidy_from_affinity(affinity)
                self._assert_finite(critic_subsidy, "critic_subsidy", step)
                alpha = self.market_alpha.to(device=h.device, dtype=gate_logits.dtype)
                capital_bias = capital_shares.view(1, 1, -1)
                capital_bias = capital_bias * (1.0 + difficulty.detach()) + critic_subsidy.detach()
                capital_bias = alpha * capital_bias.detach()
                self._assert_finite(capital_bias, "capital_bias", step)
                winners, weights, costs, adjusted_logits = router.route(
                    gate_logits=gate_logits,
                    capital_bias=capital_bias,
                    market_enabled=True,
                    training=training,
                )
            self._assert_finite(weights, "weights", step)
            self._assert_finite(costs, "costs", step)
            self._assert_finite(adjusted_logits, "adjusted_logits", step)

        if self.route_no_grad:
            diff_out = difficulty.detach()
            adjusted_out = adjusted_logits.detach()
        else:
            diff_out = difficulty
            adjusted_out = adjusted_logits

        return (
            winners.detach(),
            weights,
            costs.detach(),
            diff_out,
            affinity.detach(),
            adjusted_out,
            gate_logits.detach(),
            capital_bias.detach(),
        )

    def _build_trans_prefix_union(
        self,
        h: torch.Tensor,
        rwkv_state: torch.Tensor,
        winners: torch.Tensor,
        step: int,
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        r"""ä»…ä¸º Transformer å‘½ä¸­ token æ„å»º prefixï¼›è¿”å› prefix_union ä¸ç´¢å¼•æ˜ å°„ã€‚"""
        B, T, C = h.shape
        flat_bt = B * T
        flat_h = h.reshape(flat_bt, C)
        flat_state = rwkv_state.reshape(flat_bt, C)

        if not self.lazy_prefix_union:
            bridge_prefix = self.bridge(flat_h, flat_state)  # [B*T, P, C]
            self._assert_finite(bridge_prefix, "bridge_prefix_full", step)
            prefix_indices = torch.arange(flat_bt, device=h.device, dtype=torch.long)
            return bridge_prefix, prefix_indices

        trans_mask = (winners[:, :, 0] >= self.num_rwkv) | (winners[:, :, 1] >= self.num_rwkv)
        flat_mask = trans_mask.reshape(-1)
        prefix_indices = torch.full((flat_bt,), -1, device=h.device, dtype=torch.long)

        if not flat_mask.any():
            empty_prefix = torch.empty(
                0,
                self.bridge.max_prefix_len,
                C,
                device=h.device,
                dtype=h.dtype,
            )
            return empty_prefix, prefix_indices

        prefix_union = self.bridge(flat_h[flat_mask], flat_state[flat_mask])  # [N_u, P, C]
        self._assert_finite(prefix_union, "bridge_prefix_union", step)
        prefix_indices[flat_mask] = torch.arange(prefix_union.shape[0], device=h.device, dtype=torch.long)
        return prefix_union, prefix_indices

    def _forward_expert_stage(
        self,
        x_after_att: torch.Tensor,
        h: torch.Tensor,
        rwkv_state: torch.Tensor,
        winners: torch.Tensor,
        weights: torch.Tensor,
        step: int,
    ) -> torch.Tensor:
        r"""æ‰§è¡Œ Top-2 ä¸“å®¶æ··åˆå¹¶è¿”å› block è¾“å‡ºã€‚"""
        B, T, C = h.shape
        prefix_union, prefix_indices = self._build_trans_prefix_union(h, rwkv_state, winners, step)
        final_out = torch.zeros_like(h)  # [B, T, C]

        for rank in range(2):
            rank_winners = winners[:, :, rank]  # [B, T]
            rank_weights = weights[:, :, rank].unsqueeze(-1)  # [B, T, 1]

            for e in range(self.num_experts):
                mask = (rank_winners == e)  # [B, T]
                if not mask.any():
                    continue

                selected_h = h[mask]  # [N, C]
                selected_weights = rank_weights[mask]  # [N, 1]

                if e >= self.num_rwkv:
                    flat_mask = mask.reshape(-1)
                    if self.lazy_prefix_union:
                        sel_idx = prefix_indices[flat_mask]
                        valid = sel_idx >= 0
                        if not valid.any():
                            continue
                        expert_out = torch.zeros_like(selected_h)
                        expert_valid = self.experts[e](selected_h[valid], prefix_union[sel_idx[valid]])
                        if expert_valid.dtype != expert_out.dtype:
                            expert_valid = expert_valid.to(expert_out.dtype)
                        expert_out[valid] = expert_valid
                    else:
                        expert_out = self.experts[e](selected_h, prefix_union[flat_mask])
                else:
                    expert_out = self.experts[e](selected_h, None)
                if expert_out.dtype != selected_h.dtype:
                    expert_out = expert_out.to(selected_h.dtype)
                self._assert_finite(expert_out, f"expert_out_e{e}", step)

                weighted_out = expert_out * selected_weights
                self._assert_finite(weighted_out, f"weighted_out_e{e}", step)
                final_out[mask] += weighted_out

        self._assert_finite(final_out, "final_out", step)
        x_out = x_after_att + final_out
        self._assert_finite(x_out, "x_out", step)
        return x_out

    def forward(self, 
                x: torch.Tensor, 
                v_first: torch.Tensor,
                capital_shares: torch.Tensor,
                router: SparseRouter,
                step: int,
                warmup_steps: int,
                use_market: bool = True,
                training: bool = True,
                idx: torch.Tensor = None) -> Tuple[torch.Tensor, torch.Tensor, Dict]:
        r"""forward(x, v_first, capital_shares, router, step, warmup_steps, use_market=True, training=True, idx=None) -> Tuple[Tensor, Tensor, Dict]"""
        del warmup_steps

        if self.training and self.checkpoint_att_stage:
            x_after_att, h, v_first, rwkv_state = checkpoint(
                lambda xx, vv, ii: self._forward_att_stage(xx, vv, ii, step),
                x,
                v_first,
                idx,
                use_reentrant=False,
            )
        else:
            x_after_att, h, v_first, rwkv_state = self._forward_att_stage(x, v_first, idx, step)

        winners, weights, costs, difficulty, affinity, adjusted_logits, gate_logits, capital_bias = self._forward_route_stage(
            h, capital_shares, router, use_market, training, step
        )

        if self.training and self.checkpoint_expert_stage:
            x = checkpoint(
                lambda x0, h0, s0, w0, wt0: self._forward_expert_stage(x0, h0, s0, w0, wt0, step),
                x_after_att,
                h,
                rwkv_state,
                winners,
                weights,
                use_reentrant=False,
            )
        else:
            x = self._forward_expert_stage(x_after_att, h, rwkv_state, winners, weights, step)

        info = {
            "winners": winners,
            "weights": weights,
            "costs": costs,
            "difficulty": difficulty,
            "affinity": affinity,
            "adjusted_logits": adjusted_logits,
            "gate_logits": gate_logits,
            "capital_bias": capital_bias,
        }
        return x, v_first, info


class CaMoE_System(nn.Module):
    r"""CaMoE ä¸»ç³»ç»Ÿï¼Œå°è£…å¤šå±‚ Blockã€å¸‚åœºçŠ¶æ€ä¸æŸå¤±è®¡ç®—ã€‚"""

    def __init__(self, config: Dict) -> None:
        r"""åˆå§‹åŒ–ç³»ç»Ÿçº§æ¨¡å—ä¸å…±äº«ç»„ä»¶ã€‚"""
        super().__init__()
        self.config = config
        self.n_embd = config['n_embd']
        self.n_layer = config['n_layer']
        self.vocab_size = config['vocab_size']
        self.use_gradient_checkpoint = config.get("use_gradient_checkpoint", True)
        self.nan_debug = config.get("nan_debug", False)
        self.economy_cfg = config.get("economy", {})
        
        self.num_rwkv_experts = config.get('num_rwkv_experts', 6)
        self.num_trans_experts = config.get('num_trans_experts', 2)
        self.num_experts = self.num_rwkv_experts + self.num_trans_experts
        
        # Embedding
        self.emb = nn.Embedding(self.vocab_size, self.n_embd)

        # Shared DeepEmbed table (optional, recommended for VRAM efficiency)
        self.deep_embed = None
        if config.get("use_deep_embed_attention", False) and config.get("use_shared_deep_embed", True):
            self.deep_embed = SharedDeepEmbed(
                vocab_size=self.vocab_size,
                k_dim=min(config.get("dea_q_dim", 256), self.n_embd),
                v_dim=self.n_embd,
            )
        
        # å…±äº« Bridge
        self.bridge = UltimateBridge(
            self.n_embd, 
            config.get('prefix_len', 64),
            config.get('low_rank_dim', 64)
        )
        
        # Blocks
        self.blocks = nn.ModuleList()
        for i in range(self.n_layer):
            self.blocks.append(CaMoE_Block(
                self.n_embd,
                self.n_layer,
                i,
                config['head_size'],
                config,
                bridge=self.bridge,
                shared_deep_embed=self.deep_embed,
            ))
        
        self.ln_out = nn.LayerNorm(self.n_embd)
        
        # Head (å¯é€‰ Tied Embedding)
        if config.get('tied_embeddings', False):
            self.head = None  # ä½¿ç”¨ emb.weight
        else:
            self.head = nn.Linear(self.n_embd, self.vocab_size, bias=False)
        
        # Market
        self.capital_manager = CapitalManager(
            self.n_layer, self.num_experts,
            total_capital=config.get('total_capital', 10000.0),
            min_share=config.get('min_capital_share', 0.05),
            tax_threshold=config.get('tax_threshold', 2.0),
            tax_rate=config.get('tax_rate', 0.1),
            economy=self.economy_cfg,
        )
        
        self.router = SparseRouter(noise_std=float(config.get("router_noise_std", 0.02)))
        self.register_buffer("layer_performance_ema", torch.zeros(self.n_layer))
        self.register_buffer("last_winner_entropy", torch.zeros(self.n_layer))
        self.register_buffer("last_weight_entropy", torch.zeros(self.n_layer))
        self.register_buffer("last_market_alpha", torch.zeros(self.n_layer))
        self._critic_loss_ema = None
        self._last_critic_bonus_signal = 0.0

    def _assert_finite(self, x: torch.Tensor, name: str, step: int, layer_id: int = -1) -> None:
        r"""_assert_finite(x, name, step, layer_id=-1) -> None

        åœ¨è°ƒè¯•æ¨¡å¼ä¸‹æ ¡éªŒå¼ é‡æ•°å€¼åˆæ³•æ€§ï¼Œå‡ºç° NaN/Inf ç«‹å³æŠ›é”™å¹¶è¾“å‡ºå®šä½ä¿¡æ¯ã€‚
        """
        if (not self.nan_debug) or (x is None):
            return
        if not torch.is_floating_point(x):
            return
        if torch.isfinite(x).all():
            return

        with torch.no_grad():
            bad = ~torch.isfinite(x)
            bad_count = int(bad.sum().item())
            total = x.numel()
            finite_x = x[torch.isfinite(x)]
            if finite_x.numel() > 0:
                vmin = float(finite_x.min().item())
                vmax = float(finite_x.max().item())
            else:
                vmin = float("nan")
                vmax = float("nan")
            print(
                f"âŒ NaNDebug | step={step} | layer={layer_id} | tensor={name} | "
                f"bad={bad_count}/{total} | finite_min={vmin:.6e} | finite_max={vmax:.6e}"
            )
        raise RuntimeError(f"NaN/Inf detected at step={step}, layer={layer_id}, tensor={name}")
    
    def forward(self, idx: torch.Tensor, step: int = 0, 
                phase: str = "normal", use_market_override: bool = None) -> Tuple[torch.Tensor, Dict]:
        r"""forward(idx, step=0, phase="normal", use_market_override=None) -> Tuple[Tensor, Dict]

        æ‰§è¡Œæ•´ç½‘å‰å‘å¹¶æ”¶é›†å„å±‚è·¯ç”±ä¿¡æ¯ã€‚

        Args:
          idx (Tensor): å½¢çŠ¶ ``[B, T]`` çš„ token idã€‚
          step (int, optional): å½“å‰æ­¥æ•°ã€‚Default: ``0``ã€‚
          phase (str, optional): è®­ç»ƒé˜¶æ®µæ ‡ç­¾ã€‚Default: ``"normal"``ã€‚

        Returns:
          Tuple[Tensor, Dict]: ``logits`` ä¸å„å±‚ ``info``ã€‚
        """
        x = self.emb(idx)
        self._assert_finite(x, "emb_out", step, -1)
        v_first = None
        
        use_market = True if use_market_override is None else bool(use_market_override)
        
        all_info = {
            "winners": [],
            "costs": [],
            "difficulties": [],
            "affinities": [],
            "gate_logits": [],
            "capital_bias": [],
        }
        warmup_steps = self.config.get('warmup_steps', 2000)

        for i, block in enumerate(self.blocks):
            shares = self.capital_manager.get_shares(i)
            x, v_first, info = block(
                x, v_first, shares, self.router,
                step, warmup_steps, use_market, self.training, idx
            )

            self._assert_finite(x, "block_out", step, i)
            self._assert_finite(v_first, "v_first", step, i)
            self._assert_finite(info["costs"], "costs", step, i)
            self._assert_finite(info["difficulty"], "difficulty", step, i)
            self._assert_finite(info["affinity"], "affinity", step, i)
            self._assert_finite(info["weights"], "weights", step, i)
            self._assert_finite(info["adjusted_logits"], "adjusted_logits", step, i)
            
            all_info["winners"].append(info["winners"].detach())
            all_info["costs"].append(info["costs"].detach())
            # criticwarm éœ€è¦ difficulty ä¿ç•™ autograd å›¾æ¥è®­ç»ƒ Critic
            # å…¶å®ƒé˜¶æ®µåœ¨ block å†… route_no_grad=True æ—¶ difficulty å·²æ˜¯ detached tensor
            all_info["difficulties"].append(info["difficulty"])
            all_info["affinities"].append(info["affinity"].detach())
            all_info["gate_logits"].append(info["gate_logits"].detach())
            all_info["capital_bias"].append(info["capital_bias"].detach())

            with torch.no_grad():
                adj_prob = F.softmax(info["adjusted_logits"].float(), dim=-1)
                adj_ent = -(adj_prob * torch.log(adj_prob + 1e-9)).sum(dim=-1).mean()
                wt_prob = info["weights"].float()
                wt_ent = -(wt_prob * torch.log(wt_prob + 1e-9)).sum(dim=-1).mean()
                alpha = block.market_alpha.detach().mean()
                self.last_winner_entropy[i] = adj_ent.to(self.last_winner_entropy.dtype)
                self.last_weight_entropy[i] = wt_ent.to(self.last_weight_entropy.dtype)
                self.last_market_alpha[i] = alpha.to(self.last_market_alpha.dtype)
        
        x = self.ln_out(x)
        self._assert_finite(x, "ln_out", step, self.n_layer)
        
        # Output (Tied Embedding Rescale Trick)
        if self.head is not None:
            logits = self.head(x)
        else:
            # Tied embedding éœ€ç¼©æ”¾ï¼Œé¿å… logits å¹…åº¦è¿‡å¤§å¯¼è‡´ CE é‡çº²å¼‚å¸¸
            x = x * (self.n_embd ** -0.5)
            logits = F.linear(x, self.emb.weight)
        self._assert_finite(logits, "logits", step, self.n_layer)
        
        return logits, all_info
    
    def compute_losses(
        self,
        logits: torch.Tensor,
        targets: torch.Tensor,
        all_info: Dict,
    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, float]:
        r"""compute_losses(logits, targets, all_info) -> Tuple[Tensor, Tensor, Tensor, Tensor, float]

        è®¡ç®—ä¸»æŸå¤±ã€token çº§æŸå¤±ä»¥åŠ Critic æŸå¤±ã€‚

        Args:
          logits (Tensor): å½¢çŠ¶ ``[B, T, V]``ã€‚
          targets (Tensor): å½¢çŠ¶ ``[B, T]``ã€‚
          all_info (Dict): å„å±‚éš¾åº¦/è·¯ç”±ä¿¡æ¯ã€‚

        Returns:
          Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]:
          ``total_loss``ã€``token_losses``ã€``main_loss``ã€``critic_loss``ã€``aux_loss``ã€‚
        """
        if self.config.get("stabilize_logits", False):
            # è®­ç»ƒç¨³å®šæ€§ä¿æŠ¤ï¼šé¿å…ä¸Šæ¸¸æç«¯å€¼å¯¼è‡´ CE ç›´æ¥ NaN/Inf
            logits = torch.nan_to_num(logits, nan=0.0, posinf=30.0, neginf=-30.0)

        B, T = targets.shape
        
        # Main Loss
        main_loss = F.cross_entropy(
            logits.reshape(-1, self.vocab_size),
            targets.reshape(-1),
            ignore_index=-100,
        )
        
        # Token Losses (for Market Update)
        with torch.no_grad():
            token_losses = F.cross_entropy(
                logits.reshape(-1, self.vocab_size),
                targets.reshape(-1),
                reduction='none',
                ignore_index=-100,
            ).reshape(B, T)
            if self.config.get("stabilize_logits", False):
                token_losses = torch.nan_to_num(token_losses, nan=0.0, posinf=100.0, neginf=0.0)
            # ignore_index ä½ç½®æœ¬èº«ä¸º 0 lossï¼Œè¿™é‡Œå†æ˜¾å¼å½’é›¶ï¼Œé¿å…åç»­å¸‚åœºæ›´æ–°è¯¯ç”¨
            token_losses = token_losses.masked_fill(targets.eq(-100), 0.0)
        
        # Critic Loss
        critic_loss = 0.0
        for i, diff in enumerate(all_info.get("difficulties", [])):
            baseline = self.capital_manager.baseline_losses[i]
            target = F.relu(token_losses - baseline)
            critic_loss += F.smooth_l1_loss(diff.squeeze(-1), target)
        
        if len(all_info.get("difficulties", [])) > 0:
            critic_loss /= len(all_info["difficulties"])

        # Router Load Balance Loss
        aux_loss = torch.zeros((), device=logits.device, dtype=logits.dtype)
        n_counted = 0
        valid_mask = targets.ne(-100)
        valid_count = valid_mask.sum().item()
        if valid_count > 0:
            for i, winners_i in enumerate(all_info.get("winners", [])):
                if i >= self.n_layer:
                    break
                freq = torch.zeros(self.num_experts, device=logits.device, dtype=logits.dtype)
                for k in range(2):
                    one_hot = F.one_hot(winners_i[:, :, k], self.num_experts).to(dtype=logits.dtype)
                    one_hot = one_hot * valid_mask.unsqueeze(-1).to(dtype=logits.dtype)
                    freq = freq + one_hot.sum(dim=(0, 1))
                denom = valid_mask.sum().to(dtype=logits.dtype) * 2.0 + 1e-6
                freq = freq / denom
                target_freq = torch.tensor(1.0 / self.num_experts, device=logits.device, dtype=logits.dtype)
                aux_loss = aux_loss + ((freq - target_freq) ** 2).sum() * self.num_experts
                n_counted += 1
            if n_counted > 0:
                aux_loss = aux_loss / float(n_counted)

        aux_coeff = float(self.config.get("aux_loss_coeff", 0.01))
        total_loss = main_loss + 0.1 * critic_loss + aux_coeff * aux_loss
        
        return total_loss, token_losses, main_loss, critic_loss, aux_loss
    
    def _compute_critic_bonus_signal(self, critic_loss) -> float:
        if critic_loss is None:
            return 0.0
        curr = float(critic_loss.detach().item() if isinstance(critic_loss, torch.Tensor) else critic_loss)
        eps = 1e-6
        momentum = float(self.economy_cfg.get("critic_bonus_ema_momentum", 0.95))

        if self._critic_loss_ema is None:
            self._critic_loss_ema = curr
            return 0.0

        prev = self._critic_loss_ema
        signal = (prev - curr) / (abs(prev) + eps)
        self._critic_loss_ema = momentum * prev + (1.0 - momentum) * curr
        return float(signal)

    def _build_donor_state(self, donor_indices: torch.Tensor) -> Dict[str, torch.Tensor]:
        donor_state = {}
        if donor_indices.numel() == 0:
            return donor_state

        weights = []
        for idx in donor_indices.tolist():
            cap = torch.clamp(self.blocks[idx].critic.capital, min=1.0)
            weights.append(cap)
        weight_tensor = torch.stack(weights)
        norm_w = weight_tensor / (weight_tensor.sum() + 1e-6)

        for name, _p in self.blocks[0].critic.named_parameters():
            acc = None
            for w, idx in zip(norm_w, donor_indices.tolist()):
                src = dict(self.blocks[idx].critic.named_parameters())[name].detach()
                term = src * w.to(src.dtype)
                acc = term if acc is None else (acc + term)
            donor_state[name] = acc
        return donor_state

    def _handle_critic_bankruptcy_and_restructure(self, layer_idx: int, step: int) -> None:
        critic = self.blocks[layer_idx].critic
        threshold = float(self.economy_cfg.get("critic_bankrupt_threshold_ratio", 0.2)) * critic.init_capital
        bailout_base = float(self.economy_cfg.get("bailout_base", 1000.0))
        bailout_decay = float(self.economy_cfg.get("bailout_decay", 0.65))
        bailout_min = float(self.economy_cfg.get("bailout_min", 200.0))
        alpha = float(self.economy_cfg.get("restructure_alpha", 0.12))
        donor_topk = int(self.economy_cfg.get("donor_topk", 2))

        if float(critic.capital.item()) >= threshold:
            return

        bcount = float(critic.bailout_count.item())
        bailout = max(bailout_min, bailout_base * (bailout_decay ** bcount))
        critic.capital = critic.capital + bailout
        critic.debt = critic.debt + bailout
        critic.bailout_count = critic.bailout_count + 1

        if self.n_layer <= 1:
            return

        scores = self.layer_performance_ema.clone()
        scores[layer_idx] = -1e9
        k = min(donor_topk, self.n_layer - 1)
        donor_indices = torch.topk(scores, k=k).indices
        donor_state = self._build_donor_state(donor_indices)
        if donor_state:
            critic.restructure_from_donors(donor_state, alpha=alpha)
            print(
                f"ğŸ” CriticRestructure | step={step} | layer={layer_idx} | "
                f"donors={donor_indices.tolist()} | alpha={alpha:.3f} | "
                f"bailout={bailout:.2f} | debt={float(critic.debt.item()):.2f}"
            )

        if step % 100 == 0:
            print(f"ğŸ›ï¸ Layer {layer_idx}: Critic bailout={bailout:.2f}, debt={float(critic.debt.item()):.2f}")

    def update_market(
        self,
        all_info: Dict,
        token_losses: torch.Tensor,
        step: int,
        phase: str = "normal",
        critic_loss=None,
    ) -> None:
        r"""update_market(all_info, token_losses, step, phase="normal", critic_loss=None) -> None"""
        with torch.no_grad():
            bonus_signal = self._compute_critic_bonus_signal(critic_loss)
            bonus_clip = self.economy_cfg.get("critic_bonus_clip", (-0.1, 0.3))
            clipped_signal = float(max(float(bonus_clip[0]), min(float(bonus_clip[1]), bonus_signal)))
            self._last_critic_bonus_signal = clipped_signal

            if phase == "criticwarm":
                reward_scale = float(self.economy_cfg.get("criticwarm_reward_scale", 2.0))
                penalty_scale = float(self.economy_cfg.get("criticwarm_penalty_scale", 0.4))
                critic_bonus_scale = float(self.economy_cfg.get("critic_bonus_scale", 0.2))
            else:
                reward_scale = 1.0
                penalty_scale = 1.0
                critic_bonus_scale = 0.0

            base_commission = float(self.economy_cfg.get("base_commission", 0.8))
            dividend_scale = float(self.economy_cfg.get("dividend_scale", 0.6))
            dividend_std_factor = float(self.economy_cfg.get("dividend_std_factor", 0.5))
            repay_ratio = float(self.economy_cfg.get("repay_ratio", 0.25))
            alpha_ema = float(self.economy_cfg.get("market_alpha_ema", 0.98))
            alpha_step = float(self.economy_cfg.get("market_alpha_step", 0.2))
            alpha_min = float(self.economy_cfg.get("market_alpha_min", 0.0))
            alpha_max = float(self.economy_cfg.get("market_alpha_max", 1.0))

            for i in range(self.n_layer):
                if i >= len(all_info.get("winners", [])):
                    continue

                _cap_stats = self.capital_manager.update(
                    i,
                    all_info["winners"][i],
                    token_losses,
                    all_info["costs"][i],
                    affinity=all_info["affinities"][i],
                )

                baseline = float(self.capital_manager.baseline_losses[i].item())
                perf = baseline - float(token_losses.mean().item())
                self.layer_performance_ema[i] = 0.95 * self.layer_performance_ema[i] + 0.05 * perf

                # Alpha EMA è‡ªé€‚åº”ï¼ˆéæ¢¯åº¦ï¼‰:
                # gate ä¸ market bias è¶Šä¸€è‡´ï¼Œalpha ç›®æ ‡è¶Šé«˜ï¼›è¶Šå†²çªï¼Œalpha ç›®æ ‡è¶Šä½ã€‚
                if i < len(all_info.get("gate_logits", [])) and i < len(all_info.get("capital_bias", [])):
                    gate_logits_i = all_info["gate_logits"][i]     # [B,T,E]
                    capital_bias_i = all_info["capital_bias"][i]   # [B,T,E]
                    gate_top1 = gate_logits_i.argmax(dim=-1)
                    market_top1 = capital_bias_i.argmax(dim=-1)
                    agree = (gate_top1 == market_top1).float()
                    agree_ratio = float(agree.mean().item()) if agree.numel() > 0 else 0.5
                    curr_alpha = float(self.blocks[i].market_alpha.item())
                    alpha_target = curr_alpha + alpha_step * (agree_ratio - 0.5) * 2.0
                    alpha_target = max(alpha_min, min(alpha_max, alpha_target))
                    new_alpha = alpha_ema * curr_alpha + (1.0 - alpha_ema) * alpha_target
                    new_alpha = max(alpha_min, min(alpha_max, new_alpha))
                    self.blocks[i].market_alpha.fill_(new_alpha)

                self.blocks[i].critic.settle(
                    all_info["affinities"][i],
                    all_info["winners"][i],
                    token_losses,
                    baseline,
                    reward_scale=reward_scale,
                    penalty_scale=penalty_scale,
                    critic_bonus_scale=critic_bonus_scale,
                    bonus_clip=bonus_clip,
                    critic_loss_signal=clipped_signal,
                    base_commission=base_commission,
                    dividend_scale=dividend_scale,
                    dividend_std_factor=dividend_std_factor,
                )

                # å€ºåŠ¡è‡ªåŠ¨å¿è¿˜
                critic = self.blocks[i].critic
                if float(critic.debt.item()) > 0:
                    repay_base = torch.clamp(critic.capital - critic.init_capital * 0.2, min=0.0)
                    repay = torch.clamp(repay_base * repay_ratio, min=0.0, max=critic.debt)
                    critic.capital = critic.capital - repay
                    critic.debt = critic.debt - repay

                self._handle_critic_bankruptcy_and_restructure(i, step)
    
    def log_market_health(self) -> Dict:
        r"""log_market_health() -> Dict

        æ±‡æ€»æ‰€æœ‰å±‚çš„å¸‚åœºå¥åº·æŒ‡æ ‡ã€‚

        Returns:
          Dict: åŒ…å« RWKV/Transformer ä»½é¢ã€Giniã€Critic èµ„æœ¬ç­‰æŒ‡æ ‡ã€‚
        """
        metrics = {}
        for i in range(self.n_layer):
            caps = self.capital_manager.capitals[i]
            total_cap = caps.sum() + 1e-6
            
            rwkv_share = caps[:self.blocks[i].num_rwkv].sum() / total_cap * 100
            trans_share = caps[self.blocks[i].num_rwkv:].sum() / total_cap * 100
            
            sorted_caps, _ = torch.sort(caps)
            n = self.num_experts
            idx = torch.arange(1, n + 1, device=caps.device, dtype=caps.dtype)
            gini = ((2 * idx - n - 1) * sorted_caps).sum() / (n * total_cap + 1e-6)
            
            metrics[f"L{i}/TransShare"] = trans_share.item()
            metrics[f"L{i}/RWKVShare"] = rwkv_share.item()
            metrics[f"L{i}/Gini"] = gini.item()
            metrics[f"L{i}/CriticCap"] = self.blocks[i].critic.capital.item()
            metrics[f"L{i}/CriticDebt"] = self.blocks[i].critic.debt.item()
            metrics[f"L{i}/BailoutCount"] = self.blocks[i].critic.bailout_count.item()
            metrics[f"L{i}/AssetVelocity"] = self.capital_manager.get_asset_velocity(i).item()
            metrics[f"L{i}/QEInject"] = self.capital_manager.last_qe_inject[i].item()
            metrics[f"L{i}/QEDrain"] = self.capital_manager.last_qe_drain[i].item()
            metrics[f"L{i}/VCInject"] = self.capital_manager.last_vc_inject[i].item()
            metrics[f"L{i}/IdleTax"] = self.capital_manager.last_idle_tax[i].item()
            metrics[f"L{i}/Depreciation"] = self.capital_manager.last_depreciation[i].item()
            metrics[f"L{i}/ProfitFlow"] = self.capital_manager.last_profit_flow[i].item()
            metrics[f"L{i}/WealthTax"] = self.capital_manager.last_wealth_tax[i].item()
            metrics[f"L{i}/PerfEMA"] = self.layer_performance_ema[i].item()
            metrics[f"L{i}/CriticBonusSignal"] = float(self._last_critic_bonus_signal)
            metrics[f"L{i}/MarketAlpha"] = self.last_market_alpha[i].item()
            metrics[f"L{i}/WinnerFromAdjustedEntropy"] = self.last_winner_entropy[i].item()
            metrics[f"L{i}/WeightEntropy"] = self.last_weight_entropy[i].item()
        
        return metrics


CaMoE/market.py:
"""
CaMoE v21 Market Mechanism
Top-2 Vickrey Auction + Central Bank/QE + Idle Tax/Depreciation + Asset Velocity
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Tuple


class CapitalManager(nn.Module):
    r"""CapitalManager(...) -> None

    ç®¡ç†æ¯å±‚ä¸“å®¶èµ„æœ¬ã€ç¨æ”¶ã€æŠ˜æ—§ã€è´§å¸æ”¿ç­–å’Œèµ„äº§æµé€Ÿã€‚
    """

    def __init__(
        self,
        num_layers: int,
        num_experts: int,
        total_capital: float = 10000.0,
        min_share: float = 0.05,
        tax_threshold: float = 2.0,
        tax_rate: float = 0.1,
        economy: Dict = None,
    ) -> None:
        super().__init__()
        self.num_layers = num_layers
        self.num_experts = num_experts
        self.total_capital = float(total_capital)
        self.min_share = float(min_share)
        self.tax_threshold = float(tax_threshold)
        self.tax_rate = float(tax_rate)

        econ = economy or {}
        self.base_compute_floor_ratio = float(econ.get("base_compute_floor_ratio", 0.06))
        self.qe_low_ratio = float(econ.get("qe_low_ratio", 0.85))
        self.qe_high_ratio = float(econ.get("qe_high_ratio", 1.20))
        self.qe_inject_ratio = float(econ.get("qe_inject_ratio", 0.20))
        self.qe_drain_ratio = float(econ.get("qe_drain_ratio", 0.10))
        self.qe_floor_alloc_ratio = float(econ.get("qe_floor_alloc_ratio", 0.70))
        self.idle_threshold = float(econ.get("idle_threshold", 0.01))
        self.idle_tax_rate = float(econ.get("idle_tax_rate", 0.02))
        self.depreciation_rate = float(econ.get("depreciation_rate", 0.001))
        self.vc_affinity_threshold = float(econ.get("vc_affinity_threshold", 0.15))
        self.vc_low_cap_ratio = float(econ.get("vc_low_cap_ratio", 0.85))
        self.vc_selected_threshold = float(econ.get("vc_selected_threshold", 0.01))
        self.vc_inject_ratio = float(econ.get("vc_inject_ratio", 0.01))
        self.vc_max_inject_ratio = float(econ.get("vc_max_inject_ratio", 0.12))

        init_cap = self.total_capital / self.num_experts
        self.register_buffer("capitals", torch.ones(num_layers, num_experts) * init_cap)
        self.register_buffer("baseline_losses", torch.ones(num_layers) * 5.0)
        self.register_buffer("selection_ema", torch.zeros(num_layers, num_experts))
        self.register_buffer("asset_flow_ema", torch.zeros(num_layers))
        self.register_buffer("asset_velocity", torch.zeros(num_layers))
        self.register_buffer("last_qe_inject", torch.zeros(num_layers))
        self.register_buffer("last_qe_drain", torch.zeros(num_layers))
        self.register_buffer("last_idle_tax", torch.zeros(num_layers))
        self.register_buffer("last_depreciation", torch.zeros(num_layers))
        self.register_buffer("last_profit_flow", torch.zeros(num_layers))
        self.register_buffer("last_wealth_tax", torch.zeros(num_layers))
        self.register_buffer("last_vc_inject", torch.zeros(num_layers))

    def get_shares(self, layer_idx: int) -> torch.Tensor:
        caps = self.capitals[layer_idx]
        return caps / (caps.sum() + 1e-6)

    def _compute_guarantee_floor(self) -> float:
        floor_by_ratio = self.total_capital * self.base_compute_floor_ratio / self.num_experts
        floor_by_share = self.total_capital * self.min_share / self.num_experts
        return max(floor_by_ratio, floor_by_share)

    def apply_idle_tax_and_depreciation(self, layer_idx: int, winners: torch.Tensor) -> Dict[str, torch.Tensor]:
        r"""apply_idle_tax_and_depreciation(layer_idx, winners) -> Dict"""
        caps = self.capitals[layer_idx]
        one_hot = F.one_hot(winners, num_classes=self.num_experts).any(dim=2).float()  # [B, T, E]
        selected_rate = one_hot.mean(dim=(0, 1))
        self.selection_ema[layer_idx] = 0.95 * self.selection_ema[layer_idx] + 0.05 * selected_rate

        idle_mask = self.selection_ema[layer_idx] < self.idle_threshold
        idle_tax = caps * self.idle_tax_rate * idle_mask.to(caps.dtype)
        caps = caps - idle_tax

        depreciation = caps * self.depreciation_rate
        caps = caps - depreciation

        self.capitals[layer_idx] = caps
        self.last_idle_tax[layer_idx] = idle_tax.sum()
        self.last_depreciation[layer_idx] = depreciation.sum()

        return {
            "idle_tax": idle_tax.sum(),
            "depreciation": depreciation.sum(),
        }

    def apply_monetary_policy(self, layer_idx: int) -> Dict[str, torch.Tensor]:
        r"""apply_monetary_policy(layer_idx) -> Dict"""
        caps = self.capitals[layer_idx]
        target = torch.tensor(self.total_capital, device=caps.device, dtype=caps.dtype)
        total = caps.sum()
        floor = torch.tensor(self._compute_guarantee_floor(), device=caps.device, dtype=caps.dtype)

        inject = torch.zeros((), device=caps.device, dtype=caps.dtype)
        drain = torch.zeros((), device=caps.device, dtype=caps.dtype)

        if total < target * self.qe_low_ratio:
            inject = (target - total) * self.qe_inject_ratio
            floor_gap = torch.clamp(floor - caps, min=0.0)
            floor_gap_sum = floor_gap.sum()
            alloc = torch.zeros_like(caps)

            if floor_gap_sum > 0:
                alloc = alloc + (inject * self.qe_floor_alloc_ratio) * (floor_gap / (floor_gap_sum + 1e-6))
            else:
                alloc = alloc + (inject * self.qe_floor_alloc_ratio) / self.num_experts

            alloc = alloc + (inject * (1.0 - self.qe_floor_alloc_ratio)) / self.num_experts
            caps = caps + alloc

        elif total > target * self.qe_high_ratio:
            drain = (total - target) * self.qe_drain_ratio
            caps = caps - drain * (caps / (total + 1e-6))

        caps = torch.clamp(caps, min=floor)
        self.capitals[layer_idx] = caps
        self.last_qe_inject[layer_idx] = inject
        self.last_qe_drain[layer_idx] = drain

        return {
            "qe_inject": inject,
            "qe_drain": drain,
        }

    def get_asset_velocity(self, layer_idx: int) -> torch.Tensor:
        r"""get_asset_velocity(layer_idx) -> Tensor"""
        return self.asset_velocity[layer_idx]

    def update(
        self,
        layer_idx: int,
        winners: torch.Tensor,
        token_losses: torch.Tensor,
        costs: torch.Tensor,
        affinity: torch.Tensor = None,
    ) -> Dict[str, torch.Tensor]:
        r"""update(...) -> Dict

        è¿”å›æœ¬å±‚çš„èµ„é‡‘æµåŠ¨ä¸æ”¿ç­–ç»Ÿè®¡ã€‚
        """
        with torch.no_grad():
            avg_loss = token_losses.mean()
            self.baseline_losses[layer_idx] = 0.99 * self.baseline_losses[layer_idx] + 0.01 * avg_loss
            baseline = self.baseline_losses[layer_idx]

            caps = self.capitals[layer_idx].clone()

            one_hot = F.one_hot(winners, num_classes=self.num_experts).any(dim=2).float()  # [B, T, E]
            performance = (baseline - token_losses).unsqueeze(-1)  # [B, T, 1]
            expenses = costs.unsqueeze(-1)  # [B, T, 1]
            profit_per_expert = ((performance - expenses) * one_hot).sum(dim=(0, 1))  # [E]

            caps = caps + profit_per_expert

            # ç´¯è¿›ç¨ï¼ˆé˜²å„æ–­ï¼‰
            avg_cap = caps.mean()
            excess = torch.clamp(caps - avg_cap * self.tax_threshold, min=0.0)
            wealth_tax = excess * self.tax_rate
            caps = caps - wealth_tax
            self.last_wealth_tax[layer_idx] = wealth_tax.sum()

            self.capitals[layer_idx] = caps

            idle_stats = self.apply_idle_tax_and_depreciation(layer_idx, winners)
            qe_stats = self.apply_monetary_policy(layer_idx)

            # æœ€ç»ˆä¿éšœçº¿
            guarantee_floor = self._compute_guarantee_floor()
            self.capitals[layer_idx] = torch.clamp(self.capitals[layer_idx], min=guarantee_floor)

            # èµ„äº§æµé€Ÿï¼šå•ä½ step çš„èµ„é‡‘å‘¨è½¬å æ¯”
            flow = profit_per_expert.abs().sum()
            total_cap = self.capitals[layer_idx].sum() + 1e-6
            self.asset_flow_ema[layer_idx] = 0.95 * self.asset_flow_ema[layer_idx] + 0.05 * flow
            self.asset_velocity[layer_idx] = self.asset_flow_ema[layer_idx] / total_cap
            self.last_profit_flow[layer_idx] = flow

            vc_inject = self.apply_venture_capital(layer_idx, winners, affinity)

            return {
                "profit_flow": flow,
                "wealth_tax": self.last_wealth_tax[layer_idx],
                "idle_tax": idle_stats["idle_tax"],
                "depreciation": idle_stats["depreciation"],
                "qe_inject": qe_stats["qe_inject"],
                "qe_drain": qe_stats["qe_drain"],
                "vc_inject": vc_inject,
                "asset_velocity": self.asset_velocity[layer_idx],
            }

    def apply_venture_capital(
        self,
        layer_idx: int,
        winners: torch.Tensor,
        affinity: torch.Tensor = None,
    ) -> torch.Tensor:
        r"""apply_venture_capital(layer_idx, winners, affinity=None) -> Tensor

        è‹¥ä¸“å®¶æ»¡è¶³ã€Œé«˜ affinity + ä½èµ„æœ¬ + å‡ ä¹æœªè¢«é€‰ä¸­ã€ï¼Œæ‰§è¡Œé£æŠ•æ³¨èµ„ã€‚
        """
        caps = self.capitals[layer_idx]
        if affinity is None:
            self.last_vc_inject[layer_idx] = 0.0
            return torch.zeros((), device=caps.device, dtype=caps.dtype)

        with torch.no_grad():
            # token çº§é€‰æ‹©ç‡ï¼šTop-2 ä»»ä¸€å‘½ä¸­å³è®°ä¸ºè¢«é€‰ä¸­
            one_hot = F.one_hot(winners, num_classes=self.num_experts).any(dim=2).float()  # [B,T,E]
            selected_rate = one_hot.mean(dim=(0, 1))  # [E]

            # Critic åå¥½å¼ºåº¦ï¼ˆåªä¿ç•™æ­£å‘çœ‹å¥½ï¼‰
            aff_score = F.relu(affinity).mean(dim=(0, 1))  # [E]
            aff_gate = torch.clamp(aff_score - self.vc_affinity_threshold, min=0.0)

            avg_cap = caps.mean()
            low_cap_mask = caps < (avg_cap * self.vc_low_cap_ratio)
            low_select_mask = selected_rate < self.vc_selected_threshold
            eligible = low_cap_mask & low_select_mask & (aff_gate > 0)

            if not eligible.any():
                self.last_vc_inject[layer_idx] = 0.0
                return torch.zeros((), device=caps.device, dtype=caps.dtype)

            # â€œè¶Šç©·è¶Šå€¼å¾—æŠ•â€ï¼šåŒç­‰ affinity ä¸‹ä¼˜å…ˆä½èµ„æœ¬ä¸“å®¶
            poverty_boost = (avg_cap / (caps + 1e-6)).clamp(min=0.5, max=5.0)
            score = aff_gate * poverty_boost * eligible.to(caps.dtype)
            score_sum = score.sum()
            if score_sum <= 0:
                self.last_vc_inject[layer_idx] = 0.0
                return torch.zeros((), device=caps.device, dtype=caps.dtype)

            budget = torch.tensor(self.total_capital * self.vc_inject_ratio, device=caps.device, dtype=caps.dtype)
            alloc = budget * (score / (score_sum + 1e-6))
            max_each = torch.tensor(
                self.total_capital * self.vc_max_inject_ratio / self.num_experts,
                device=caps.device,
                dtype=caps.dtype,
            )
            alloc = torch.clamp(alloc, min=0.0, max=max_each)
            inject = alloc.sum()

            self.capitals[layer_idx] = caps + alloc
            self.last_vc_inject[layer_idx] = inject
            return inject


class SparseRouter:
    r"""SparseRouter(noise_std=0.02) -> None

    åŸºäº Top-2 Vickrey æ‹å–çš„ç¨€ç–è·¯ç”±å™¨ã€‚
    """

    def __init__(self, noise_std: float = 0.02) -> None:
        self.noise_std = noise_std

    def route(
        self,
        gate_logits: torch.Tensor,
        capital_bias: torch.Tensor = None,
        market_enabled: bool = True,
        training: bool = True,
    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
        B, T, _E = gate_logits.shape

        # 1) winner åˆ†æ”¯ï¼šadjusted logitsï¼ˆå¯å«å¸‚åœºåç½®ï¼‰
        adjusted_logits = gate_logits
        if capital_bias is not None:
            adjusted_logits = adjusted_logits + capital_bias
        winner_logits = adjusted_logits
        if training:
            winner_logits = winner_logits + torch.randn_like(winner_logits) * self.noise_std

        topk_vals, topk_idxs = torch.topk(winner_logits, 3, dim=-1)
        winners = topk_idxs[:, :, :2]
        if market_enabled:
            # å¸‚åœºå¼€å¯æ—¶æ²¿ç”¨ Vickrey é£æ ¼ç¬¬äºŒä»·æ ¼ï¼ˆè¿™é‡Œç”¨ Top-3ï¼‰
            costs = topk_vals[:, :, 2]
        else:
            costs = torch.zeros(B, T, device=gate_logits.device, dtype=gate_logits.dtype)

        # 2) weight åˆ†æ”¯ï¼šçº¯ Gate ä¸»å¯¼ï¼ˆä¸å¼•å…¥å¸‚åœºæ¢¯åº¦ï¼‰
        top2_gate = torch.gather(gate_logits, dim=-1, index=winners)
        weights = F.softmax(top2_gate, dim=-1)

        # è¿”å›æ— å™ªå£° adjusted logits ä½œä¸ºè°ƒè¯•ä¿¡å·
        return winners, weights, costs, adjusted_logits


CaMoE/critic.py:
"""
CaMoE v20 Critic (VC Mode)
æ”¯æŒåˆ†é˜¶æ®µå¥–åŠ±ç¼©æ”¾ã€å€ºåŠ¡é‡ç»„ä¸ç ´äº§åå‚æ•°æ¼‚ç§»
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Tuple


class CriticVC(nn.Module):
    r"""CriticVC(n_embd, num_experts, init_capital=10000.0) -> None"""

    def __init__(self, n_embd: int, num_experts: int, init_capital: float = 10000.0) -> None:
        super().__init__()
        self.num_experts = num_experts
        self.init_capital = init_capital

        self.feature = nn.Sequential(
            nn.Linear(n_embd, 128),
            nn.LayerNorm(128),
            nn.GELU(),
        )

        self.difficulty_head = nn.Sequential(
            nn.Linear(128, 64),
            nn.GELU(),
            nn.Linear(64, 1),
            nn.Softplus(),
        )

        self.affinity_head = nn.Sequential(
            nn.Linear(128, 64),
            nn.GELU(),
            nn.Linear(64, num_experts),
        )

        self.register_buffer("capital", torch.tensor(float(init_capital)))
        self.register_buffer("prediction_accuracy", torch.tensor(0.5))
        self.register_buffer("debt", torch.tensor(0.0))
        self.register_buffer("bailout_count", torch.tensor(0.0))

    def forward(self, h: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        feat = self.feature(h)
        difficulty = self.difficulty_head(feat) + 1e-3
        affinity = self.affinity_head(feat)
        return difficulty, affinity

    def apply_to_bids(self, bids: torch.Tensor, affinity: torch.Tensor) -> torch.Tensor:
        return bids + self.subsidy_from_affinity(affinity)

    def subsidy_from_affinity(self, affinity: torch.Tensor) -> torch.Tensor:
        capital_ratio = (self.capital / self.init_capital).clamp(0.1, 2.0)
        return affinity * capital_ratio * 0.05

    def restructure_from_donors(self, donor_state: Dict[str, torch.Tensor], alpha: float = 0.12) -> None:
        r"""restructure_from_donors(donor_state, alpha=0.12) -> None

        å°†å½“å‰ Critic å‚æ•°å‘ donor critic çŠ¶æ€æ¼‚ç§»ï¼ˆç ´äº§é‡ç»„ï¼‰ã€‚
        """
        if donor_state is None or len(donor_state) == 0:
            return
        alpha = float(alpha)
        with torch.no_grad():
            for name, p in self.named_parameters():
                donor = donor_state.get(name, None)
                if donor is None:
                    continue
                p.data.lerp_(donor.to(device=p.device, dtype=p.dtype), alpha)

    def settle(
        self,
        affinity: torch.Tensor,
        winners: torch.Tensor,
        token_losses: torch.Tensor,
        baseline: float,
        reward_scale: float = 1.0,
        penalty_scale: float = 1.0,
        critic_bonus_scale: float = 0.0,
        bonus_clip: Tuple[float, float] = (-0.2, 0.4),
        critic_loss_signal: float = 0.0,
        base_commission: float = 1.0,
        dividend_scale: float = 0.0,
        dividend_std_factor: float = 0.5,
    ) -> Dict:
        r"""settle(...) -> Dict

        é»˜è®¤å‚æ•°ä¸æ—§ç‰ˆæœ¬å…¼å®¹ï¼›æ–°å¢å‚æ•°ç”¨äº v20 åˆ†é˜¶æ®µç»æµè°ƒåˆ¶ã€‚
        """
        with torch.no_grad():
            _B, _T, E = affinity.shape
            amounts = affinity.abs() * 0.05
            directions = torch.sign(affinity)

            total_cost = amounts.sum()
            total_revenue = torch.zeros((), device=affinity.device, dtype=affinity.dtype)
            correct = torch.zeros((), device=affinity.device, dtype=affinity.dtype)
            total = torch.zeros((), device=affinity.device, dtype=affinity.dtype)

            perf = baseline - token_losses
            good = perf > 0

            # åˆ†çº¢ï¼šæ˜¾è‘—ä¼˜äºå…¨åœºå¹³å‡æ—¶é¢å¤–åŠ æˆ
            perf_mean = perf.mean()
            perf_std = perf.std(unbiased=False)
            dividend_gate = perf > (perf_mean + dividend_std_factor * perf_std)
            dividend_mul = 1.0 + dividend_scale * torch.clamp(perf - perf_mean, min=0.0)

            for e in range(E):
                won = (winners == e).any(dim=-1)
                lost = ~won

                amt = amounts[:, :, e]
                direction = directions[:, :, e]
                is_long = direction > 0
                is_short = direction < 0

                # åšå¤šï¼šå¥–åŠ± good+wonï¼Œå¼±åŒ– lost
                long_win_good = is_long & won & good
                long_lost = is_long & lost

                # åšç©ºï¼šå¥–åŠ± short+lost åŠ short+won+bad
                short_lost = is_short & lost
                short_win_bad = is_short & won & ~good
                short_win_good = is_short & won & good

                # å¥–åŠ±é¡¹
                rev_long_good = (amt[long_win_good] * 1.5 * reward_scale)
                rev_short_lost = (amt[short_lost] * 1.3 * reward_scale)
                rev_short_win_bad = (amt[short_win_bad] * 1.2 * reward_scale)

                # æƒ©ç½š/ä¿åº•é¡¹
                rev_long_lost = (amt[long_lost] * 0.5 * penalty_scale)
                rev_short_win_good = (amt[short_win_good] * 0.2 * penalty_scale)

                if dividend_scale > 0:
                    rev_long_good = rev_long_good * dividend_mul[long_win_good]
                    rev_short_lost = rev_short_lost * dividend_mul[short_lost]
                    rev_short_win_bad = rev_short_win_bad * dividend_mul[short_win_bad]
                    rev_long_lost = rev_long_lost * (1.0 + 0.25 * dividend_gate[long_lost].to(rev_long_lost.dtype))
                    rev_short_win_good = rev_short_win_good * (1.0 + 0.25 * dividend_gate[short_win_good].to(rev_short_win_good.dtype))

                total_revenue = (
                    total_revenue
                    + rev_long_good.sum()
                    + rev_short_lost.sum()
                    + rev_short_win_bad.sum()
                    + rev_long_lost.sum()
                    + rev_short_win_good.sum()
                )

                correct = correct + long_win_good.sum() + short_lost.sum() + short_win_bad.sum()
                total = total + (is_long | is_short).sum()

            # å¸¸è§„åˆ†çº¢åˆ¶ï¼šå¹³æ—¶åˆ†æˆé™ä½
            total_revenue = total_revenue * float(base_commission)

            # CriticLoss å¥–åŠ±ï¼šloss ä¸‹é™è¶Šå¿«ï¼Œå¥–åŠ±è¶Šé«˜
            signal = torch.tensor(float(critic_loss_signal), device=affinity.device, dtype=affinity.dtype)
            signal = torch.clamp(signal, min=float(bonus_clip[0]), max=float(bonus_clip[1]))
            bonus_factor = torch.clamp(1.0 + float(critic_bonus_scale) * signal, min=0.1, max=2.0)

            profit = total_revenue * bonus_factor - total_cost
            self.capital = (self.capital + profit).clamp(100.0, self.init_capital * 3)

            if total > 0:
                acc = correct / (total + 1e-6)
                self.prediction_accuracy = 0.95 * self.prediction_accuracy + 0.05 * acc

            return {
                "profit": float(profit.item()),
                "capital": float(self.capital.item()),
                "bonus_factor": float(bonus_factor.item()),
            }


CaMoE/experts.py:
"""
CaMoE v18 Experts
RWKV FFN + Linear Transformer
"""

import torch
import torch.nn as nn
import torch.nn.functional as F


class SparseRWKVFFN(nn.Module):
    r"""SparseRWKVFFN(n_embd, expand=4) -> None

    RWKV é£æ ¼ ReLU^2 FFN ä¸“å®¶ï¼ˆæ— çŠ¶æ€ç‰ˆæœ¬ï¼‰ã€‚

    Args:
      n_embd (int): è¾“å…¥/è¾“å‡ºé€šé“ç»´åº¦ã€‚
      expand (int, optional): FFN æ‰©å±•å€ç‡ã€‚Default: ``4``ã€‚
    """

    def __init__(self, n_embd: int, expand: int = 4) -> None:
        super().__init__()
        hidden = n_embd * expand
        self.key = nn.Linear(n_embd, hidden, bias=False)
        self.value = nn.Linear(hidden, n_embd, bias=False)
        
        self.confidence = nn.Sequential(
            nn.Linear(n_embd, 64),
            nn.GELU(), 
            nn.Linear(64, 1), 
            nn.Sigmoid()
        )
        
        # Init
        self.value.weight.data.zero_()
        nn.init.orthogonal_(self.key.weight.data, gain=2.0)
    
    def get_confidence(self, x: torch.Tensor) -> torch.Tensor:
        r"""get_confidence(x) -> Tensor

        è®¡ç®— token çº§ä¸“å®¶ç½®ä¿¡åº¦ã€‚

        Args:
          x (Tensor): å½¢çŠ¶ ``[B, T, C]``ã€‚

        Returns:
          Tensor: å½¢çŠ¶ ``[B, T]`` çš„ç½®ä¿¡åº¦ã€‚
        """
        return self.confidence(x).squeeze(-1)
        
    def forward(self, x: torch.Tensor, prefix: torch.Tensor = None) -> torch.Tensor:
        r"""forward(x, prefix=None) -> Tensor

        æ‰§è¡Œ FFN å‰å‘ã€‚

        Args:
          x (Tensor): å½¢çŠ¶ ``[N, C]``ã€‚
          prefix (Tensor, optional): å ä½å‚æ•°ï¼ŒRWKV ä¸“å®¶ä¸ä½¿ç”¨ã€‚Default: ``None``ã€‚

        Returns:
          Tensor: å½¢çŠ¶ ``[N, C]`` çš„ä¸“å®¶è¾“å‡ºã€‚
        """
        k = torch.relu(self.key(x)) ** 2
        out = self.value(k)
        return out


class LinearTransformerExpert(nn.Module):
    r"""LinearTransformerExpert(n_embd, n_head) -> None

    ä½¿ç”¨ Bridge Prefix ä½œä¸º K/V çš„çº¿æ€§ Transformer ä¸“å®¶ã€‚

    Args:
      n_embd (int): è¾“å…¥/è¾“å‡ºç»´åº¦ã€‚
      n_head (int): æ³¨æ„åŠ›å¤´æ•°ã€‚
    """

    def __init__(self, n_embd: int, n_head: int) -> None:
        super().__init__()
        self.n_head = n_head
        self.head_dim = n_embd // n_head
        
        self.q = nn.Linear(n_embd, n_embd, bias=False)
        self.k = nn.Linear(n_embd, n_embd, bias=False)
        self.v = nn.Linear(n_embd, n_embd, bias=False)
        self.o = nn.Linear(n_embd, n_embd, bias=False)
        self.gate = nn.Linear(n_embd, n_embd)
        
        self.confidence = nn.Sequential(
            nn.Linear(n_embd, 64),
            nn.GELU(), 
            nn.Linear(64, 1), 
            nn.Sigmoid()
        )
        
        # Init: æŠ‘åˆ¶è¾“å‡º
        nn.init.orthogonal_(self.o.weight, gain=0.1)

    def get_confidence(self, x: torch.Tensor) -> torch.Tensor:
        r"""get_confidence(x) -> Tensor

        Args:
          x (Tensor): å½¢çŠ¶ ``[B, T, C]``ã€‚

        Returns:
          Tensor: å½¢çŠ¶ ``[B, T]`` çš„ç½®ä¿¡åº¦ã€‚
        """
        return self.confidence(x).squeeze(-1)

    def forward(self, x: torch.Tensor, prefix: torch.Tensor) -> torch.Tensor:
        r"""forward(x, prefix) -> Tensor

        Args:
          x (Tensor): å½¢çŠ¶ ``[N, C]``ï¼ŒQuery æ¥æºã€‚
          prefix (Tensor): å½¢çŠ¶ ``[N, P, C]``ï¼Œç”± Bridge ç”Ÿæˆçš„ Key/Value æ¥æºã€‚

        Returns:
          Tensor: å½¢çŠ¶ ``[N, C]`` çš„ä¸“å®¶è¾“å‡ºã€‚
        """
        N, C = x.shape
        H, D = self.n_head, self.head_dim
        P = prefix.shape[1]
        
        # Linear Attention
        q = self.q(x).reshape(N, 1, H, D)
        k = self.k(prefix).reshape(N, P, H, D)
        v = self.v(prefix).reshape(N, P, H, D)
        
        out = F.scaled_dot_product_attention(
            q.transpose(1, 2),  # [N, H, 1, D]
            k.transpose(1, 2),  # [N, H, P, D]
            v.transpose(1, 2),  # [N, H, P, D]
            is_causal=False
        )
        
        out = out.transpose(1, 2).reshape(N, C)
        
        # Gating
        g = torch.sigmoid(self.gate(x))
        out = self.o(out) * g
        
        return out


CaMoE/bridge.py:
"""
CaMoE v18 Bridge
Linear-State Bridge with Low-Rank Projection
"""

import torch
import torch.nn as nn
import torch.nn.functional as F


class UltimateBridge(nn.Module):
    r"""UltimateBridge(n_embd, max_prefix_len=64, low_rank_dim=64) -> None

    å°† RWKV éšçŠ¶æ€æ˜ å°„ä¸º Transformer ä¸“å®¶å¯ç”¨çš„å‰ç¼€è¡¨ç¤ºã€‚

    Args:
      n_embd (int): éšçŠ¶æ€ç»´åº¦ã€‚
      max_prefix_len (int, optional): å‰ç¼€ token é•¿åº¦ã€‚Default: ``64``ã€‚
      low_rank_dim (int, optional): ä½ç§©ä¸­é—´ç»´åº¦ã€‚Default: ``64``ã€‚
    """

    def __init__(self, n_embd: int, max_prefix_len: int = 64, low_rank_dim: int = 64) -> None:
        super().__init__()
        self.max_prefix_len = max_prefix_len
        self.n_embd = n_embd
        self.low_rank_dim = low_rank_dim
        
        # 1. å‹ç¼©/èåˆå±‚ [N, 2C] -> [N, 2C]
        self.compressor = nn.Sequential(
            nn.Linear(n_embd * 2, n_embd * 2),
            nn.LayerNorm(n_embd * 2),
            nn.GELU()
        )
        
        # 2. Low-Rank ç”Ÿæˆå±‚
        # [N, 2C] -> [N, prefix_len * low_rank_dim]
        self.generator_low = nn.Linear(n_embd * 2, max_prefix_len * self.low_rank_dim)
        
        # 3. ä¸Šé‡‡æ · [low_rank_dim -> n_embd]
        self.upsample = nn.Linear(self.low_rank_dim, n_embd, bias=False)
        
        # 4. ä½ç½®ç¼–ç  [1, prefix_len, n_embd]
        self.pos_emb = nn.Parameter(torch.zeros(1, max_prefix_len, n_embd))
        nn.init.trunc_normal_(self.pos_emb, std=0.02)
        
        self.norm = nn.LayerNorm(n_embd)

    def forward(self, x: torch.Tensor, rwkv_state: torch.Tensor) -> torch.Tensor:
        r"""forward(x, rwkv_state) -> Tensor

        Args:
          x (Tensor): å½¢çŠ¶ ``[N, C]``ï¼Œå½“å‰ token ç‰¹å¾ã€‚
          rwkv_state (Tensor): å½¢çŠ¶ ``[N, C]``ï¼ŒRWKV çŠ¶æ€è¡¨ç¤ºã€‚

        Returns:
          Tensor: å½¢çŠ¶ ``[N, prefix_len, C]`` çš„ prefixã€‚
        """
        N, C = x.shape
        
        # å…³é”®ï¼šä¸å† detachï¼Œè®©æ¢¯åº¦æµå› RWKV Backbone
        combined = torch.cat([x, rwkv_state], dim=-1)
        
        # èåˆç‰¹å¾
        feat = self.compressor(combined)
        
        # ç”Ÿæˆ Low-Rank å‰ç¼€
        # [N, 2C] -> [N, prefix_len * low_rank_dim] -> [N, prefix_len, low_rank_dim]
        low_feat = self.generator_low(feat).reshape(N, self.max_prefix_len, self.low_rank_dim)
        
        # ä¸Šé‡‡æ ·å›é«˜ç»´ç©ºé—´
        # [N, prefix_len, low_rank_dim] -> [N, prefix_len, C]
        prefix = self.upsample(low_feat)
        
        # æ³¨å…¥ä½ç½®ä¿¡æ¯ & Norm
        prefix = prefix + self.pos_emb
        prefix = self.norm(prefix)
        
        return prefix


CaMoE/backbone.py:
"""
RWKV-7 TimeMix Backbone (Turbo Edition with ClampW Kernel)
æ”¯æŒ BF16 åŸç”ŸåŠ é€Ÿ
"""

import torch
import torch.nn as nn
from torch.nn import functional as F
from torch.utils.cpp_extension import load
import math
import os
from typing import Tuple

# ==================== CUDA Kernel ====================
HEAD_SIZE = 64
CHUNK_LEN = 16
USE_CUDA = False
RUN_CUDA_RWKV7 = None
CUDA_KERNEL_EXPECTS_FP32 = False
W_SCALE = -math.exp(-0.5)

def init_rwkv7_cuda():
    r"""init_rwkv7_cuda() -> None

    ç¼–è¯‘å¹¶æ³¨å†Œ RWKV7 è‡ªå®šä¹‰ CUDA ç®—å­ã€‚

    æˆåŠŸåä¼šè®¾ç½®å…¨å±€ ``USE_CUDA=True`` å¹¶ç»‘å®š ``RUN_CUDA_RWKV7``ã€‚
    """
    global USE_CUDA, RUN_CUDA_RWKV7, CUDA_KERNEL_EXPECTS_FP32
    
    try:
        curr_dir = os.path.dirname(os.path.abspath(__file__))
        cuda_dir = os.path.join(curr_dir, 'cuda')
        
        # æ–°æ–‡ä»¶å
        cu_file = os.path.join(cuda_dir, 'rwkv7_clampw.cu')
        cpp_file = os.path.join(cuda_dir, 'rwkv7_clampw.cpp')
        
        if not (os.path.exists(cu_file) and os.path.exists(cpp_file)):
            print(f"âš ï¸ CUDA files not found: {cu_file}")
            print("   Using Fallback (Slow FP32)...")
            return
        
        # ç¼–è¯‘æ ‡å¿—ï¼šå¦‚æœä¸åŠ  -D_FP32_ï¼Œé»˜è®¤å°±æ˜¯ BF16
        # æ³¨æ„ï¼šHEAD_SIZE å’Œ CHUNK_LEN ä¾ç„¶è¦ä¼ 
        use_fast_math = os.environ.get("CAMOE_DISABLE_FAST_MATH", "0") != "1"
        force_fp32_kernel = os.environ.get("CAMOE_FORCE_FP32_KERNEL", "0") == "1"

        flags = [
            '-res-usage', 
            f'-D_N_={HEAD_SIZE}', 
            f"-D_CHUNK_LEN_={CHUNK_LEN}", 
            "-O3",  
            "--extra-device-vectorization"
        ]
        if use_fast_math:
            flags.append("--use_fast_math")
        if force_fp32_kernel:
            flags.append("-D_FP32_")
        cxx_flags = ["-D_FP32_"] if force_fp32_kernel else []
        print(f"ğŸ”§ RWKV CUDA flags: fast_math={use_fast_math}, fp32_kernel={force_fp32_kernel}")
        
        ext_name = "rwkv7_clampw"
        load(
            name=ext_name, 
            sources=[cu_file, cpp_file], 
            is_python_module=False, 
            verbose=True, 
            extra_cuda_cflags=flags,
            extra_cflags=cxx_flags,
        )
        # TORCH_LIBRARY namespace is fixed in rwkv7_clampw.cpp
        op_ns = torch.ops.rwkv7_clampw
        
        class RWKV7_ClampW(torch.autograd.Function):
            @staticmethod
            def forward(ctx, r, w, k, v, a, b):
                B, T, H, C = r.shape
                assert T % CHUNK_LEN == 0
                expected_dtype = torch.float32 if force_fp32_kernel else torch.bfloat16
                assert all(i.dtype == expected_dtype for i in [r, w, k, v, a, b]), "RWKV7 kernel dtype mismatch"
                assert all(i.is_contiguous() for i in [r, w, k, v, a, b]), "RWKV7 kernel needs contiguous tensors"
                
                # åˆ›å»ºè¾“å‡ºå’ŒçŠ¶æ€å¼ é‡
                # æ³¨æ„ï¼šBF16 Kernel è¦æ±‚è¾“å…¥è¾“å‡ºæ˜¯ BF16/FP16ï¼Œä½† State æ˜¯ FP32
                y = torch.empty_like(v)
                s = torch.empty(B, H, T//CHUNK_LEN, C, C, dtype=torch.float32, device=r.device)
                sa = torch.empty(B, T, H, C, dtype=torch.float32, device=r.device)
                
                op_ns.forward(r, w, k, v, a, b, y, s, sa)
                ctx.save_for_backward(r, w, k, v, a, b, s, sa)
                return y
            
            @staticmethod
            def backward(ctx, dy):
                expected_dtype = torch.float32 if force_fp32_kernel else torch.bfloat16
                assert dy.dtype == expected_dtype, "RWKV7 backward dtype mismatch"
                assert dy.is_contiguous(), "RWKV7 backward needs contiguous dy"
                r, w, k, v, a, b, s, sa = ctx.saved_tensors
                dr, dw, dk, dv, da, db = [torch.empty_like(x) for x in [r, w, k, v, a, b]]
                op_ns.backward(r, w, k, v, a, b, dy, s, sa, dr, dw, dk, dv, da, db)
                return dr, dw, dk, dv, da, db
        
        def _run_cuda(r, w, k, v, a, b):
            B, T, HC = r.shape
            H = HC // HEAD_SIZE
            orig_dtype = r.dtype
            target_dtype = torch.float32 if CUDA_KERNEL_EXPECTS_FP32 else torch.bfloat16
            
            # View å˜æ¢
            # å…³é”®æ”¹åŠ¨ï¼šä¸å†å¼ºåˆ¶è½¬ .float() (FP32)
            # ä¿æŒåŸæœ‰çš„ dtype (BF16)ï¼Œåªåš contiguous å’Œ view
            r, w, k, v, a, b = [
                x.to(dtype=target_dtype).contiguous().view(B, T, H, HEAD_SIZE)
                for x in [r, w, k, v, a, b]
            ]
            
            out = RWKV7_ClampW.apply(r, w, k, v, a, b)
            out = out.view(B, T, HC).to(orig_dtype)
            return out
        
        RUN_CUDA_RWKV7 = _run_cuda
        USE_CUDA = True
        CUDA_KERNEL_EXPECTS_FP32 = force_fp32_kernel
        print(
            f"âœ… RWKV-7 CUDA Kernel (ClampW + {'FP32' if force_fp32_kernel else 'BF16'}) Ready"
        )
        
    except Exception as e:
        print(f"âš ï¸ CUDA init failed: {e}")


# ==================== RWKV-7 TimeMix ====================
class RWKV7_TimeMix(nn.Module):
    """
    RWKV-7 TimeMix (Attention equivalent)
    å®Œæ•´å®ç°åŠ¨æ€çŠ¶æ€æ¼”åŒ–
    """
    
    def __init__(self, n_embd: int, n_layer: int, layer_id: int, head_size: int = 64):
        super().__init__()
        self.layer_id = layer_id
        self.n_layer = n_layer
        self.head_size = head_size
        self.n_head = n_embd // head_size
        self.n_embd = n_embd
        
        assert n_embd % head_size == 0
        
        C = n_embd
        H = self.n_head
        N = head_size
        
        with torch.no_grad():
            ratio_0_to_1 = layer_id / max(n_layer - 1, 1)
            ratio_1_to_almost0 = 1.0 - (layer_id / n_layer)
            
            ddd = torch.ones(1, 1, C)
            for i in range(C):
                ddd[0, 0, i] = i / C
            
            self.x_r = nn.Parameter(1.0 - torch.pow(ddd, 0.2 * ratio_1_to_almost0))
            self.x_w = nn.Parameter(1.0 - torch.pow(ddd, 0.9 * ratio_1_to_almost0))
            self.x_k = nn.Parameter(1.0 - torch.pow(ddd, 0.7 * ratio_1_to_almost0))
            self.x_v = nn.Parameter(1.0 - torch.pow(ddd, 0.7 * ratio_1_to_almost0))
            self.x_a = nn.Parameter(1.0 - torch.pow(ddd, 0.9 * ratio_1_to_almost0))
            self.x_g = nn.Parameter(1.0 - torch.pow(ddd, 0.2 * ratio_1_to_almost0))
            
            def ortho_init(x, scale):
                shape = x.shape
                if len(shape) == 2:
                    gain = math.sqrt(shape[0] / shape[1]) if shape[0] > shape[1] else 1
                    nn.init.orthogonal_(x, gain=gain * scale)
                return x
            
            # æŒ‰RWKV-7è§„èŒƒè®¾ç½®LORAç»´åº¦
            D_DECAY_LORA = max(32, int(round((2.5 * (C ** 0.5)) / 32) * 32))
            D_AAA_LORA = max(32, int(round((2.5 * (C ** 0.5)) / 32) * 32))
            D_MV_LORA = max(32, int(round((1.7 * (C ** 0.5)) / 32) * 32))
            D_GATE_LORA = max(32, int(round((5 * (C ** 0.5)) / 32) * 32))
            
            # Decay
            www = torch.zeros(C)
            zigzag = torch.zeros(C)
            linear = torch.zeros(C)
            for n in range(C):
                linear[n] = n / (C - 1) - 0.5
                zigzag[n] = ((n % N) - ((N - 1) / 2)) / ((N - 1) / 2)
                zigzag[n] = zigzag[n] * abs(zigzag[n])
                www[n] = -6 + 6 * (n / (C - 1)) ** (1 + 1 * ratio_0_to_1 ** 0.3)
            
            self.w0 = nn.Parameter(www.reshape(1, 1, C) + 0.5 + zigzag * 2.5)
            self.w1 = nn.Parameter(torch.zeros(C, D_DECAY_LORA))
            self.w2 = nn.Parameter(ortho_init(torch.zeros(D_DECAY_LORA, C), 0.1))
            
            # AAA (in-context learning rate)
            self.a0 = nn.Parameter(torch.zeros(1, 1, C) - 0.19 + zigzag * 0.3 + linear * 0.4)
            self.a1 = nn.Parameter(torch.zeros(C, D_AAA_LORA))
            self.a2 = nn.Parameter(ortho_init(torch.zeros(D_AAA_LORA, C), 0.1))
            
            # Value residual
            self.v0 = nn.Parameter(torch.zeros(1, 1, C) + 0.73 - linear * 0.4)
            self.v1 = nn.Parameter(torch.zeros(C, D_MV_LORA))
            self.v2 = nn.Parameter(ortho_init(torch.zeros(D_MV_LORA, C), 0.1))
            
            # Gate
            self.g1 = nn.Parameter(torch.zeros(C, D_GATE_LORA))
            self.g2 = nn.Parameter(ortho_init(torch.zeros(D_GATE_LORA, C), 0.1))
            
            # Key normalization
            self.k_k = nn.Parameter(torch.zeros(1, 1, C) + 0.71 - linear * 0.1)
            self.k_a = nn.Parameter(torch.zeros(1, 1, C) + 1.02)
            self.r_k = nn.Parameter(torch.zeros(H, N) - 0.04)
        
        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))
        self.receptance = nn.Linear(C, C, bias=False)
        self.key = nn.Linear(C, C, bias=False)
        self.value = nn.Linear(C, C, bias=False)
        self.output = nn.Linear(C, C, bias=False)
        self.ln_x = nn.GroupNorm(H, C, eps=64e-5)
        
        # åˆå§‹åŒ–æƒé‡
        with torch.no_grad():
            self.receptance.weight.data.uniform_(-0.5/(C**0.5), 0.5/(C**0.5))
            self.key.weight.data.uniform_(-0.05/(C**0.5), 0.05/(C**0.5))
            self.value.weight.data.uniform_(-0.5/(C**0.5), 0.5/(C**0.5))
            self.output.weight.data.zero_()

    @staticmethod
    def _report_nonfinite(x: torch.Tensor, name: str, layer_id: int) -> None:
        if torch.isfinite(x).all():
            return
        with torch.no_grad():
            bad = ~torch.isfinite(x)
            bad_count = int(bad.sum().item())
            total = x.numel()
            finite_x = x[torch.isfinite(x)]
            if finite_x.numel() > 0:
                vmin = float(finite_x.min().item())
                vmax = float(finite_x.max().item())
            else:
                vmin = float("nan")
                vmax = float("nan")
            print(
                f"âŒ NaNDebug-TimeMix | layer={layer_id} | tensor={name} | "
                f"bad={bad_count}/{total} | finite_min={vmin:.6e} | finite_max={vmax:.6e}"
            )

    @staticmethod
    def _run_torch_fallback(
        r: torch.Tensor,
        w_raw: torch.Tensor,
        k: torch.Tensor,
        v: torch.Tensor,
        a: torch.Tensor,
        b: torch.Tensor,
        n_head: int,
        head_size: int,
    ) -> torch.Tensor:
        r"""çº¯ PyTorch çš„ TimeMix é€’æ¨å®ç°ï¼Œç”¨äº CUDA kernel å¼‚å¸¸æ—¶çš„åº”æ€¥è·¯å¾„ã€‚"""
        B, T, C = r.shape
        H, N = n_head, head_size
        r = r.view(B, T, H, N).float()
        w_raw = w_raw.view(B, T, H, N).float()
        k = k.view(B, T, H, N).float()
        v = v.view(B, T, H, N).float()
        a = a.view(B, T, H, N).float()
        b = b.view(B, T, H, N).float()

        # ä¸ CUDA kernel ä¿æŒåŒæ ·çš„ w å˜æ¢
        w = torch.exp(W_SCALE / (1.0 + torch.exp(-w_raw)))

        state = torch.zeros(B, H, N, N, device=r.device, dtype=torch.float32)
        ys = []
        for t in range(T):
            rt = r[:, t]  # [B,H,N]
            wt = w[:, t]
            kt = k[:, t]
            vt = v[:, t]
            at = a[:, t]
            bt = b[:, t]

            sa = (state * at.unsqueeze(-2)).sum(dim=-1)  # [B,H,N_i]
            state = (
                state * wt.unsqueeze(-2)
                + sa.unsqueeze(-1) * bt.unsqueeze(-2)
                + vt.unsqueeze(-1) * kt.unsqueeze(-2)
            )
            yt = (state * rt.unsqueeze(-2)).sum(dim=-1)  # [B,H,N_i]
            ys.append(yt)

        y = torch.stack(ys, dim=1).reshape(B, T, C)
        return y.to(r.dtype)
    
    def forward(
        self, x: torch.Tensor, v_first: torch.Tensor = None
    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        r"""forward(x, v_first=None) -> Tuple[Tensor, Tensor, Tensor]

        æ‰§è¡Œ RWKV-7 TimeMix ä¸»å¹²å‰å‘ã€‚

        Args:
          x (Tensor): å½¢çŠ¶ ``[B, T, C]``ã€‚
          v_first (Tensor, optional): é¦–å±‚ value ç¼“å­˜ã€‚Default: ``None``ã€‚

        Returns:
          Tuple[Tensor, Tensor, Tensor]:
          è¾“å‡º ``out``ã€æ›´æ–°åçš„ ``v_first``ã€ä»¥åŠä¸­é—´çŠ¶æ€ ``state_representation``ã€‚
        """
        B, T, C = x.size()
        H = self.n_head
        N = self.head_size
        
        # Token shift
        xx = self.time_shift(x) - x
        
        xr = x + xx * self.x_r
        xw = x + xx * self.x_w
        xk = x + xx * self.x_k
        xv = x + xx * self.x_v
        xa = x + xx * self.x_a
        xg = x + xx * self.x_g
        
        r = self.receptance(xr)
        w = -F.softplus(-(self.w0 + torch.tanh(xw @ self.w1) @ self.w2)) - 0.5
        k = self.key(xk)
        v = self.value(xv)
        
        # Value residual (layer 0 stores, others use)
        if self.layer_id == 0:
            v_first = v.clone()
        else:
            if v_first is not None:
                v = v + (v_first - v) * torch.sigmoid(self.v0 + (xv @ self.v1) @ self.v2)
        
        a = torch.sigmoid(self.a0 + (xa @ self.a1) @ self.a2)
        g = torch.sigmoid(xg @ self.g1) @ self.g2
        
        kk = k * self.k_k
        kk = F.normalize(kk.view(B, T, H, -1), dim=-1, p=2.0).view(B, T, C)
        k = k * (1 + (a - 1) * self.k_a)
        
        # RWKV-7 åŠ¨æ€çŠ¶æ€æ¼”åŒ–
        use_fallback = os.environ.get("CAMOE_FORCE_TIMEMIX_FALLBACK", "0") == "1"
        if (not use_fallback) and USE_CUDA and RUN_CUDA_RWKV7 is not None:
            x_att = RUN_CUDA_RWKV7(r, w, k, v, -kk, kk * a)
        else:
            x_att = self._run_torch_fallback(r, w, k, v, -kk, kk * a, self.n_head, self.head_size)
        if os.environ.get("CAMOE_NAN_DEBUG", "0") == "1":
            self._report_nonfinite(x_att, "x_att_raw", self.layer_id)
        if os.environ.get("CAMOE_SANITIZE_TIMEMIX_OUT", "0") == "1":
            x_att = torch.nan_to_num(x_att, nan=0.0, posinf=0.0, neginf=0.0)

            
        state_representation = x_att.clone() 
        x_att = self.ln_x(x_att.view(B * T, C)).view(B, T, C)
        if os.environ.get("CAMOE_NAN_DEBUG", "0") == "1":
            self._report_nonfinite(x_att, "x_att_ln", self.layer_id)
        
        # Bonus term
        x_att = x_att + (
            (r.view(B, T, H, -1) * k.view(B, T, H, -1) * self.r_k)
            .sum(dim=-1, keepdim=True) * v.view(B, T, H, -1)
        ).view(B, T, C)
        
        out = self.output(x_att * g)
        if os.environ.get("CAMOE_NAN_DEBUG", "0") == "1":
            self._report_nonfinite(out, "att_out", self.layer_id)
        
        return out, v_first , state_representation


# ==================== DeepEmbed + DeepEmbedAttention (from RWKV-7 Goose) ====================
# æ€æƒ³ï¼šç”¨ã€Œè¯è¡¨çº§ã€åµŒå…¥å¯¹ K/V åšé€ token è°ƒåˆ¶ï¼Œå¹¶å¢åŠ ä¸€æ¡å› æœ Self-Attention åˆ†æ”¯ï¼ˆQ/K/V token-shift + soft-capï¼‰


class SharedDeepEmbed(nn.Module):
    """
    å…¨æ¨¡å‹å…±äº«çš„ DeepEmbed è¡¨ã€‚
    é€šè¿‡è·¨å±‚å…±äº«ï¼Œå°†è¯è¡¨å‚æ•°ä» O(n_layer * vocab * dim) é™ä¸º O(vocab * dim)ã€‚
    """

    def __init__(self, vocab_size: int, k_dim: int, v_dim: int):
        super().__init__()
        self.k_emb = nn.Embedding(vocab_size, k_dim)
        self.v_emb = nn.Embedding(vocab_size, v_dim)
        nn.init.normal_(self.k_emb.weight, std=0.02)
        nn.init.normal_(self.v_emb.weight, std=0.02)

    def forward(self, idx: torch.Tensor):
        r"""forward(idx) -> Tuple[Tensor, Tensor]

        Args:
          idx (Tensor): å½¢çŠ¶ ``[B, T]`` çš„ token idã€‚

        Returns:
          Tuple[Tensor, Tensor]: ``k_emb(idx)`` ä¸ ``v_emb(idx)``ã€‚
        """
        return self.k_emb(idx), self.v_emb(idx)


class DeepEmbedAttention(nn.Module):
    """
    DeepEmbedAttention (DEA)ï¼šä¸ TimeMix å¹¶è¡Œçš„å› æœ Self-Attention åˆ†æ”¯ã€‚
    - Q/K/V ç» DeepEmbedï¼ˆk_emb, v_emb æŒ‰ token id æŸ¥è¡¨ï¼‰è°ƒåˆ¶
    - Q/K/V åš token-shiftï¼ˆä¸ä¸Šä¸€ä½ç½®æ··åˆï¼‰
    - ä½¿ç”¨ soft-cap: 64 * tanh(scores / 1024) å† softmax
    """
    
    def __init__(
        self,
        n_embd: int,
        n_layer: int,
        layer_id: int,
        head_size: int,
        vocab_size: int,
        shared_deep_embed: nn.Module = None,
        q_dim: int = 256,
        kv_dim: int = 32,
        score_scale: float = 1024.0,
        cap_scale: float = 64.0,
    ):
        super().__init__()
        self.layer_id = layer_id
        self.n_embd = n_embd
        self.q_dim = min(q_dim, n_embd)
        self.kv_dim = min(kv_dim, self.q_dim)
        self.score_scale = float(score_scale)
        self.cap_scale = float(cap_scale)
        C = n_embd

        # RWKV-8 é£æ ¼ä½ç»´è·¯å¾„ï¼šQ(C->q_dim), K/V(C->kv_dim->up)
        self.qq = nn.Linear(C, self.q_dim, bias=False)
        self.k = nn.Linear(C, self.kv_dim, bias=False)
        self.k_up = nn.Linear(self.kv_dim, self.q_dim, bias=False)
        self.v = nn.Linear(C, self.kv_dim, bias=False)
        self.v_up = nn.Linear(self.kv_dim, C, bias=False)

        # DeepEmbedï¼šé»˜è®¤ä½¿ç”¨è·¨å±‚å…±äº«è¡¨ï¼›æœªæä¾›åˆ™å›é€€ä¸ºå±‚å†…è¡¨
        self.shared_deep_embed = shared_deep_embed
        if self.shared_deep_embed is None:
            self.k_emb = nn.Embedding(vocab_size, self.q_dim)
            self.v_emb = nn.Embedding(vocab_size, C)
            nn.init.normal_(self.k_emb.weight, std=0.02)
            nn.init.normal_(self.v_emb.weight, std=0.02)
        else:
            self.k_emb = None
            self.v_emb = None
        
        # Token-shift ç³»æ•°ï¼ˆä¸ backbone time_shift ç±»ä¼¼ï¼‰
        with torch.no_grad():
            ratio_1_to_almost0 = 1.0 - (layer_id / max(n_layer, 1))
            ddd_q = torch.ones(1, 1, self.q_dim)
            ddd_v = torch.ones(1, 1, C)
            for i in range(self.q_dim):
                ddd_q[0, 0, i] = i / max(self.q_dim - 1, 1)
            for i in range(C):
                ddd_v[0, 0, i] = i / max(C - 1, 1)
            self.x_q = nn.Parameter(1.0 - torch.pow(ddd_q, 0.2 * ratio_1_to_almost0))
            self.x_k = nn.Parameter(1.0 - torch.pow(ddd_q, 0.7 * ratio_1_to_almost0))
            self.x_v = nn.Parameter(1.0 - torch.pow(ddd_v, 0.7 * ratio_1_to_almost0))

        self.ln_q = nn.LayerNorm(self.q_dim)
        self.ln_k = nn.LayerNorm(self.q_dim)
        self.ln_v = nn.LayerNorm(C)
        
        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))
        
        with torch.no_grad():
            self.qq.weight.data.uniform_(-0.5 / (C ** 0.5), 0.5 / (C ** 0.5))
            self.k.weight.data.uniform_(-0.05 / (C ** 0.5), 0.05 / (C ** 0.5))
            self.k_up.weight.data.uniform_(-0.05 / (self.kv_dim ** 0.5), 0.05 / (self.kv_dim ** 0.5))
            self.v.weight.data.uniform_(-0.05 / (C ** 0.5), 0.05 / (C ** 0.5))
            self.v_up.weight.data.uniform_(-0.05 / (self.kv_dim ** 0.5), 0.05 / (self.kv_dim ** 0.5))
    
    def forward(self, x: torch.Tensor, idx: torch.Tensor) -> torch.Tensor:
        r"""forward(x, idx) -> Tensor

        Args:
          x (Tensor): å½¢çŠ¶ ``[B, T, C]``ã€‚
          idx (Tensor): å½¢çŠ¶ ``[B, T]`` çš„ token idã€‚

        Returns:
          Tensor: å½¢çŠ¶ ``[B, T, C]`` çš„ DEA åˆ†æ”¯è¾“å‡ºã€‚
        """
        B, T, C = x.shape
        if self.shared_deep_embed is not None:
            k_emb, v_emb = self.shared_deep_embed(idx)
        else:
            k_emb = self.k_emb(idx)
            v_emb = self.v_emb(idx)

        # Q
        q = self.qq(x)
        q_prev = self.time_shift(q) - q
        q = q + q_prev * self.x_q
        q = self.ln_q(q)
        
        # K: C -> kv_dim -> q_dimï¼Œå†ç”± token çº§ DeepEmbed è°ƒåˆ¶
        k = self.k_up(self.k(x)) * k_emb
        k_prev = self.time_shift(k) - k
        k = k + k_prev * self.x_k
        k = self.ln_k(k)
        
        # V: C -> kv_dim -> Cï¼Œä¿ç•™ tanh éçº¿æ€§åè°ƒåˆ¶
        v = torch.tanh(self.v_up(self.v(x))) * v_emb
        v_prev = self.time_shift(v) - v
        v = v + v_prev * self.x_v
        v = self.ln_v(v)
        
        # Causal self-attention with soft-cap
        scores = (q @ k.transpose(-2, -1)) / self.score_scale
        scores = self.cap_scale * torch.tanh(scores)
        causal_mask = torch.triu(
            torch.ones(T, T, device=x.device, dtype=torch.bool), diagonal=1
        )
        scores = scores.masked_fill(causal_mask.unsqueeze(0), float("-inf"))
        attn = F.softmax(scores.float(), dim=-1).to(scores.dtype)
        out = attn @ v
        return out

